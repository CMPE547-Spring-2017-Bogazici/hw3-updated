{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Name: M. Kutay Yabas\n",
    "\n",
    "I hereby declare that I observed the honour code of the university when preparing the homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Programming Homework 3\n",
    "\n",
    "In this exercise we model a string of text using a Markov(1) model. For simplicity we only consider letters 'a-z'. Capital letters 'A-Z' are mapped to the corresponding ones. All remaining letters, symbols, numbers, including spaces, are denoted by '.'.\n",
    "\n",
    "\n",
    "We have a probability table $T$ where $T_{i,j} = p(x_t = j | x_{t-1} = i)$  transition model of letters in English text for $t=1,2 \\dots N$. Assume that the initial letter in a string is always a space denoted as $x_0 = \\text{'.'}$. Such a model where the probability table is always the same is sometimes called a stationary model.\n",
    "\n",
    "1. For a given $N$, write a program to sample random strings with letters $x_1, x_2, \\dots, x_N$ from $p(x_{1:N}|x_0)$\n",
    "1. Now suppose you are given strings with missing letters, where each missing letter is denoted by a question mark (or underscore, as below). Implement a method, that samples missing letters conditioned on observed ones, i.e., samples from $p(x_{-\\alpha}|x_{\\alpha})$ where $\\alpha$ denotes indices of observed letters. For example, if the input is 't??.', we have $N=4$ and\n",
    "$x_1 = \\text{'t'}$ and $x_4 = \\text{'.'}$, $\\alpha=\\{1,4\\}$ and $-\\alpha=\\{2,3\\}$. Your program may possibly generate the strings 'the.', 'twi.', 'tee.', etc. Hint: make sure to make use all data given and sample from the correct distribution. Implement the method and print the results for the test strings below. \n",
    "1. Describe a method for filling in the gaps by estimating the most likely letter for each position. Hint: you need to compute\n",
    "$$\n",
    "x_{-\\alpha}^* = \\arg\\max_{x_{-\\alpha}} p(x_{-\\alpha}|x_{\\alpha})\n",
    "$$\n",
    "Implement the method and print the results for the following test strings along with the log-probability  $\\log p(x_{-\\alpha}^*,x_{\\alpha})$.\n",
    "1. Discuss how you can improve the model to get better estimations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_strings = ['th__br__n.f_x.', '_u_st__n_.to_be._nsw_r__','i__at_._a_h_n_._e_r_i_g','q___t.___z._____t.__.___.__.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Hint: The code below loads a table of transition probabilities for English text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$p(x_t = \\text{'u'} | x_{t-1} = \\text{'q'})$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9949749\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$p(x_t | x_{t-1} = \\text{'a'})$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, Latex\n",
    "\n",
    "alphabet = [chr(i+ord('a')) for i in range(26)]\n",
    "alphabet.append('.')\n",
    "letter2idx = {c:i for i,c in enumerate(alphabet)}\n",
    "\n",
    "T = []\n",
    "with open('transitions.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        T.append(row)\n",
    "\n",
    "print('Example')\n",
    "## p(x_t = 'u' | x_{t-1} = 'q')\n",
    "display(Latex(r\"$p(x_t = \\text{'u'} | x_{t-1} = \\text{'q'})$\"))\n",
    "print(T[letter2idx['q']][letter2idx['u']])\n",
    "display(Latex(r\"$p(x_t | x_{t-1} = \\text{'a'})$\"))\n",
    "# for c,p in zip(alphabet,T[letter2idx['a']]):\n",
    "#     print(c,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some tools that are going to be usefull\n",
    "M = pd.DataFrame(T).astype(\"float\")\n",
    "M[letter2idx['a']].max()\n",
    "M[letter2idx['a']].argmax()\n",
    "idx2letter = {i:c for i,c in enumerate(alphabet)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1\n",
    "\n",
    "Given that $p(x_{1:N}|x_0)$;\n",
    "\n",
    "$p(x_{1:N}|x_0) = p(x_{1}|x_{0} = x_{0}')p(x_{2}|x_{1})...p(x_{N}|x_{N-1}) $\n",
    "\n",
    "The only conditional is $p(x_{1}|x_{0} = x_{0}')$. In this case $x_{0}' = .$\n",
    "Starting from \".\" we can make random choices according to the probability distribution of the Transition Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".amis.t.ayofooubusis.achby.tun.mpe.l.s.th.e.ghe.ndeched.o.f.be.ces.th.ee.d.ited.th.gspitsevitilersog.th.aig.w.apan.se.tis.blad.litantyos.wheshe.estheave.thedsthers.ing.i.weetansim.pe.o.hrereveisaming.tassancas.wherithitrontom.eng.ny.he.t.d..rgrdincal.g.bughier.th.oudsped.th.hinth.wee.whar.medle.acowarmeder.me.e.areat.han.ceas.f.oupong.dars..oet.an.foninse.t.tma.stry.tsatheded.thed.msindit.bomod.s..f.of.arend.theron.cithe.ous.d.internud.wa.asth.tatung.astomme.manerseractherwimond.atimannche.oous.fateatime.s.hen.ce.ldur.the.remorof.ct.coveyofoulls..ans.athaue.stortling.lde.iesou.be.es.julag.igllpot.outherendivo.tscch.thatsasdwar.mes.hegindes..tigucarinomppe.tharino.savoly.tito.ilenof.isousthe.wepomeas.is.n.pes.pendevneapex.f.bo.in..s.ant.hucrnchimeanseesos.we.w.mutol..ghth.by.cti.r.ethothembongendemeercedima.powasin.owoousthy.wale.hy.a.blde.clly.at.iay.ts.rdld.d.therre.bexcthoume..lyon.ce.os.tir.d.husut.o.thashe.toff.ergnd.oped.t.dangrmoostr.cul.hake.aby.d.th.s.h.was..dint.ndof.br.tceie.t\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def guess_xk(x0):\n",
    "    x = random.uniform(0, 1)\n",
    "    cumulative_probability = 0.0\n",
    "    for item, item_probability in zip(alphabet,  T[letter2idx[x0]]):\n",
    "        cumulative_probability += float(item_probability)\n",
    "        if x < cumulative_probability: break\n",
    "    return item\n",
    "    # numpy.random.choice have a bug in weights. After trying for some time I have foudn this algorithm from\n",
    "    # https://www.safaribooksonline.com/library/view/python-cookbook-2nd/0596007973/ch04s22.html\n",
    "    # Now i realized that it may be related to Python2&3 Differences.\n",
    "\n",
    "def generate(N=10,x0=\".\"):\n",
    "    string = x0 # x0\n",
    "    for i in range(N):\n",
    "        string = string + guess_xk(string[-1])\n",
    "    return string\n",
    "\n",
    "print( generate(1000) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2\n",
    "\n",
    "In this part our model is in the form\n",
    "\n",
    "For states from 0 to N\n",
    "\n",
    "$p(x_{1:N-1}|x_{0}=x_{0}',x_{N}=x_{N}') \\propto p(x_{N}=x_{N}'|x_{1:N-1},x_{0}=x_{0}')p(x_{N-1}|x_{N-2},x_{0}=x_{0}')...p(x_{1}|x_{0}=x_{0}') $\n",
    "\n",
    "\n",
    "$p(x_{1}|x_{0}=x_{0}',x_{N}=x_{N}')=\\sum_{x_{2}:x_{N-1}}\n",
    "p(x_{N}=x_{N}'|x_{N-1})...p(x_{2}|x_{1})p(x_{1}|x_{0}=x_{0}')$\n",
    "\n",
    "which is;\n",
    "\n",
    "T is the transition matrix\n",
    "\n",
    "$p(x_{N}=x_{N}'|x{N-1})T^{N-2}p(x_{1}|x_{0}=x_{0}') $\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def guess(b,m,e): #beginnig char, missing length, end char\n",
    "    if b is \"\":\n",
    "        b = '.'\n",
    "    mpow = np.linalg.matrix_power(M,m)\n",
    "    prob = M[letter2idx[b]].dot(mpow)*(M[letter2idx[e]])        \n",
    "    prob = prob / prob.sum(axis=0)\n",
    "\n",
    "    x = random.uniform(0, 1)\n",
    "    cumulative_probability = 0.0\n",
    "    for item, item_probability in zip(alphabet,  prob.values):\n",
    "        cumulative_probability += float(item_probability)\n",
    "        if x < cumulative_probability: break\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th.abrain.fex.\n",
      "ouestaeno.toabe.inswurle\n",
      "i.tats.lathany.reardiig\n",
      "qcnst.uizz..ei.nt.en.ees.an.\n"
     ]
    }
   ],
   "source": [
    "predict = [list(string) for string in test_strings]\n",
    "for string in predict:\n",
    "    #print(\"\".join(string))\n",
    "    i = 0\n",
    "    m = 0 #missing count\n",
    "    b = \"\"\n",
    "    e = \"\"\n",
    "    while i < len(string):\n",
    "        if string[i] == \"_\":\n",
    "            m+=1\n",
    "        else:\n",
    "            if m == 0:\n",
    "                b = string[i] #beginnig char\n",
    "            if m > 0:\n",
    "                e = string[i] #ending char\n",
    "                for j in range(m):\n",
    "                    g = guess(b,m,e)\n",
    "                    b = g\n",
    "                    string[i-(j+1)] = g\n",
    "                    #print(\"\".join(string))\n",
    "                m = 0\n",
    "        i+=1\n",
    "        if i == len(string) and m > 0:\n",
    "            #print (e,m)\n",
    "            for j in range(m):\n",
    "                g = guess_xk(e)\n",
    "                e = g\n",
    "                string[i-(j+1)] = g\n",
    "                #print(\"\".join(string))\n",
    "    print(\"\".join(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3\n",
    "\n",
    "Same as part 2 but we will get the argmax in every iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th__br__n.f_x.\n",
      "th_.br__n.f_x.\n",
      "the.br__n.f_x.\n",
      "the.br_in.f_x.\n",
      "the.br.in.f_x.\n",
      "the.br.in.fex.\n",
      "logprob -5.09978757921\n",
      "_u_st__n_.to_be._nsw_r__\n",
      "ou_st__n_.to_be._nsw_r__\n",
      "ou.st__n_.to_be._nsw_r__\n",
      "ou.st_in_.to_be._nsw_r__\n",
      "ou.st.in_.to_be._nsw_r__\n",
      "ou.st.int.to_be._nsw_r__\n",
      "ou.st.int.to.be._nsw_r__\n",
      "ou.st.int.to.be.insw_r__\n",
      "ou.st.int.to.be.inswur__\n",
      "ou.st.int.to.be.inswurq_\n",
      "ou.st.int.to.be.inswurqx\n",
      "logprob -15.7117569057\n",
      "i__at_._a_h_n_._e_r_i_g\n",
      "i_.at_._a_h_n_._e_r_i_g\n",
      "ie.at_._a_h_n_._e_r_i_g\n",
      "ie.att._a_h_n_._e_r_i_g\n",
      "ie.att..a_h_n_._e_r_i_g\n",
      "ie.att..ath_n_._e_r_i_g\n",
      "ie.att..athin_._e_r_i_g\n",
      "ie.att..athint._e_r_i_g\n",
      "ie.att..athint.he_r_i_g\n",
      "ie.att..athint.heer_i_g\n",
      "ie.att..athint.heer.i_g\n",
      "ie.att..athint.heer.ing\n",
      "logprob -16.008142732\n",
      "q___t.___z._____t.__.___.__.\n",
      "q__.t.___z._____t.__.___.__.\n",
      "q_e.t.___z._____t.__.___.__.\n",
      "qhe.t.___z._____t.__.___.__.\n",
      "qhe.t.__rz._____t.__.___.__.\n",
      "qhe.t._erz._____t.__.___.__.\n",
      "qhe.t.herz._____t.__.___.__.\n",
      "qhe.t.herz.____.t.__.___.__.\n",
      "qhe.t.herz.___e.t.__.___.__.\n",
      "qhe.t.herz.__he.t.__.___.__.\n",
      "qhe.t.herz._the.t.__.___.__.\n",
      "qhe.t.herz..the.t.__.___.__.\n",
      "qhe.t.herz..the.t._e.___.__.\n",
      "qhe.t.herz..the.t.he.___.__.\n",
      "qhe.t.herz..the.t.he.__e.__.\n",
      "qhe.t.herz..the.t.he._he.__.\n",
      "qhe.t.herz..the.t.he.the.__.\n",
      "qhe.t.herz..the.t.he.the._e.\n",
      "qhe.t.herz..the.t.he.the.he.\n",
      "logprob -24.8297346272\n"
     ]
    }
   ],
   "source": [
    "def guess_ml(b,m,e): #beginnig char, missing length, end char\n",
    "    if b is \"\":\n",
    "        b = '.'\n",
    "    mpow = np.linalg.matrix_power(M,m)\n",
    "    prob = M[letter2idx[b]].dot(mpow)*(M[letter2idx[e]])        \n",
    "    prob = prob / prob.sum(axis=0)\n",
    "    return idx2letter[prob.argmax()], np.log(prob.max())\n",
    "\n",
    "def guess_xk_ml(b):\n",
    "    return idx2letter[ M[letter2idx[b]].argmax()], np.log( M[letter2idx[b]].max())\n",
    "    \n",
    "\n",
    "predict = [list(string) for string in test_strings]\n",
    "for string in predict:\n",
    "    sum_log_prog = 0\n",
    "    print(\"\".join(string))\n",
    "    i = 0\n",
    "    m = 0 #missing count\n",
    "    b = \"\"\n",
    "    e = \"\"\n",
    "    while i < len(string):\n",
    "        if string[i] == \"_\":\n",
    "            m+=1\n",
    "        else:\n",
    "            if m == 0:\n",
    "                b = string[i] #beginnig char\n",
    "            if m > 0:\n",
    "                e = string[i] #ending char\n",
    "                for j in range(m):\n",
    "                    #print(b,m,e)\n",
    "                    g, log_prob = guess_ml(b,m,e)\n",
    "                    sum_log_prog += log_prob\n",
    "                    e = g\n",
    "                    string[i-(j+1)] = g\n",
    "                    print(\"\".join(string))\n",
    "                m = 0\n",
    "        i+=1\n",
    "        if i == len(string) and m > 0:\n",
    "            #print (e,m)\n",
    "            for j in range(m):\n",
    "                g, log_prob = guess_xk_ml(e) # last char we have\n",
    "                sum_log_prog += log_prob\n",
    "                e = g\n",
    "                string[i-(m-j)] = g\n",
    "                print(\"\".join(string))\n",
    "    print(\"logprob\",sum_log_prog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4\n",
    "Markov 1 model is not enough to catch phonetic sounds of the english language. A deeper model will work better. As the capital letters are mapped to lower letters, information about the transition at the beginning of sentences are lost. Distribution of word lenghts might be useful, for example a single letter word of arbitrary charachters is impossible other than 'a' and 'I'. Common doubles, suffix and prefixes might also be benefical."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
