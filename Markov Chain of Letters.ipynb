{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Name: Ozan Bulut\n",
    "\n",
    "I hereby declare that I observed the honour code of the university when preparing the homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Solution to 16.3-5 and 18\n",
    "[Your solutions come here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Pr?gr?mm?ng?H?m?w?rk 3\n",
    "\n",
    "In this exercise we model a string of text using a Markov(1) model. For simplicity we only consider letters 'a-z'. Capital letters 'A-Z' are mapped to the corresponding ones. All remaining letters, symbols, numbers, including spaces, are denoted by '.'.\n",
    "\n",
    "\n",
    "We have a probability table $T$ where $T_{i,j} = p(x_t = j | x_{t-1} = i)$  transition model of letters in English text for $t=1,2 \\dots N$. Assume that the initial letter in a string is always a space denoted as $x_0 = \\text{'.'}$. Such a model where the probability table is always the same is sometimes called a stationary model.\n",
    "\n",
    "1. For a given $N$, write a program to sample random strings with letters $x_1, x_2, \\dots, x_N$ from $p(x_{1:N}|x_0)$\n",
    "1. Now suppose you are given strings with missing letters, where each missing letter is denoted by a question mark (or underscore, as below). Implement a method, that samples missing letters conditioned on observed ones, i.e., samples from $p(x_{-\\alpha}|x_{\\alpha})$ where $\\alpha$ denotes indices of observed letters. For example, if the input is 't??.', we have $N=4$ and\n",
    "$x_1 = \\text{'t'}$ and $x_4 = \\text{'.'}$, $\\alpha=\\{1,4\\}$ and $-\\alpha=\\{2,3\\}$. Your program may possibly generate the strings 'the.', 'twi.', 'tee.', etc. Hint: make sure to make use all data given and sample from the correct distribution. Implement the method and print the results for the test strings below. \n",
    "1. Describe a method for filling in the gaps by estimating the most likely letter for each position. Hint: you need to compute\n",
    "$$\n",
    "x_{-\\alpha}^* = \\arg\\max_{x_{-\\alpha}} p(x_{-\\alpha}|x_{\\alpha})\n",
    "$$\n",
    "Implement the method and print the results for the following test strings along with the log-probability  $\\log p(x_{-\\alpha}^*,x_{\\alpha})$.\n",
    "1. Discuss how you can improve the model to get better estimations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_strings = ['th__br__n.f_x.', '_u_st__n_.to_be._nsw_r__','i__at_._a_h_n_._e_r_i_g','q___t.___z._____t.__.___.__.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Hint: The code below loads a table of transition probabilities for English text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$p(x_t = \\text{'u'} | x_{t-1} = \\text{'q'})$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9949749\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$p(x_t | x_{t-1} = \\text{'a'})$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 0.0002835\n",
      "b 0.0228302\n",
      "c 0.0369041\n",
      "d 0.0426290\n",
      "e 0.0012216\n",
      "f 0.0075739\n",
      "g 0.0171385\n",
      "h 0.0014659\n",
      "i 0.0372661\n",
      "j 0.0002353\n",
      "k 0.0110124\n",
      "l 0.0778259\n",
      "m 0.0260757\n",
      "n 0.2145354\n",
      "o 0.0005459\n",
      "p 0.0195213\n",
      "q 0.0001749\n",
      "r 0.1104770\n",
      "s 0.0934290\n",
      "t 0.1317960\n",
      "u 0.0098029\n",
      "v 0.0306574\n",
      "w 0.0088799\n",
      "x 0.0009562\n",
      "y 0.0233701\n",
      "z 0.0018701\n",
      ". 0.0715219\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from IPython.display import display, Latex\n",
    "\n",
    "alphabet = [chr(i+ord('a')) for i in range(26)]\n",
    "alphabet.append('.')\n",
    "letter2idx = {c:i for i,c in enumerate(alphabet)}\n",
    "letterInv = {letter2idx[i]:i for i in letter2idx.keys()}\n",
    "\n",
    "\n",
    "T = []\n",
    "with open('transitions.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        T.append(row)\n",
    "\n",
    "print('Example')\n",
    "## p(x_t = 'u' | x_{t-1} = 'q')\n",
    "display(Latex(r\"$p(x_t = \\text{'u'} | x_{t-1} = \\text{'q'})$\"))\n",
    "print(T[letter2idx['q']][letter2idx['u']])\n",
    "display(Latex(r\"$p(x_t | x_{t-1} = \\text{'a'})$\"))\n",
    "for c,p in zip(alphabet,T[letter2idx['a']]):\n",
    "    print(c,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Part 1\n",
    "Because the distribution is markovian, we only need to consider previous letter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m.re.ngd.se.ts\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "T=np.array(T).astype(np.float)\n",
    "\n",
    "def trivial_case(x0):\n",
    "    normalised = T[letter2idx[x0]]/np.sum(T[letter2idx[x0]][:])\n",
    "    return np.random.choice(alphabet,p=normalised)\n",
    "\n",
    "seq = \".\"\n",
    "for i in range(1,15):\n",
    "    seq += trivial_case(seq[-1])\n",
    "print (seq[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "\n",
    "In this part, I've modelled the situation where middle of the string is missing. Let's say we know start charecter $X_0$ and last character $X_{N+1}$. Middle of the string $X_{1:N}$ is modelled in this form:\n",
    "$$p(X_{1:N}|X_0=x_0,X_{N+1}=x_{N+1}) = \\frac{p(X_{1:N},X_0=x_0,X_{N+1}=x_{N+1})}{p(X_0=x_0,X_{N+1}=x_{N+1})} = \n",
    "\\frac{{p(X_{1:N},X_{N+1}=x_{N+1},X_0=x_0)} }{ \\sum_{1:N}{p(x_{0:N+1})}} $$ \n",
    "because the model is Markov(1) using following equation\n",
    "$$ \n",
    "p(X_{0:N+1}) = p(X_0)\\prod_1^{N+1}{p(X_i|X_{i-1})} \n",
    "$$\n",
    "we can derive\n",
    "$$ \n",
    "p(X_{1:N}|X_0=x_0,X_{N+1}=x_{N+1}) = \\frac{p(X_0=x_0)p(X_1|X_0=x_0)\\prod_2^{N}{p(X_i|X_{i-1})}p(X_{N+1}=x_{N+1}|X_N) }{p(X_0=x_0) p(X_{N+1}=x_{N+1})}=\n",
    "\\frac{p(X_1|X_0=x_0)p(X_{N+1}=x_{N+1}|X_N)\\prod_2^{N}{p(X_i|X_{i-1})}}{p(X_{N+1}=x_{N+1})}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "power_list = [T] # pre compute powers of the matrix\n",
    "for i in range(1,20):\n",
    "    power_list.append(np.multiply(power_list[-1],T))\n",
    "\n",
    "def nontrivial_case(N,x0,xN):\n",
    "    power_matrix = power_list[N]\n",
    "    last_matrix = (T[:][letter2idx[xN]])\n",
    "    matrix = np.multiply(power_matrix,last_matrix)\n",
    "    normalised = matrix[letter2idx[x0]][:]/np.sum(matrix[letter2idx[x0]][:])\n",
    "    return np.random.choice(alphabet,p=normalised)\n",
    "\n",
    "def generate(st):\n",
    "    str = list(\".\"+st)\n",
    "    left=1\n",
    "    right=1\n",
    "    while left<len(str):\n",
    "        if(str[left]=='_'):\n",
    "            if  right<left:\n",
    "                right=left\n",
    "            while right<len(str) and str[right]=='_':\n",
    "                right+=1\n",
    "            if right<len(str):\n",
    "                str[left]=nontrivial_case(right-left,str[left-1],str[right])\n",
    "            else:\n",
    "                str[left] = trivial_case(str[left-1])\n",
    "        left+=1\n",
    "    return ''.join(str[1:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "therbre.n.f.x.\n",
      "therbre.n.f.x.\n",
      "therbr.an.f.x.\n",
      "therbr.tn.fex.\n",
      "the.br.tn.f.x.\n",
      "tu.st.tnt.toube.answiram\n",
      "tutst.tn..toube.snswero.\n",
      "ru.st.ant.toube..nswerpe\n",
      "autst.an..toube.tnsw.rg.\n",
      "tutst.tn..toube.insweres\n",
      "in.ato.ta.h.n..ce.rrisg\n",
      "in.ath.caihend.terroing\n",
      "intat..taihon...e.rei.g\n",
      "it.at..tanhent.ae.rei.g\n",
      "insath.taihen..seer.ing\n",
      "quret.ouaz.the.ht.as.at..th.\n",
      "quret.a.az.the.ht..w.and.at.\n",
      "qur.t.aloz.an.s.t.th.tha.t..\n",
      "qutht.alez.an.a.t.t..t.a.an.\n",
      "qur.t.ie.z.the.ot.th.tha.th.\n"
     ]
    }
   ],
   "source": [
    "for i in test_strings:\n",
    "    for j in range(1,6):\n",
    "        print(generate(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def arg_nontrivial_case(N,x0,xN):\n",
    "    power_matrix = power_list[N]\n",
    "    last_matrix = (T[:][letter2idx[xN]])\n",
    "    matrix = np.multiply(power_matrix,last_matrix)\n",
    "    normalised = matrix[letter2idx[x0]][:]/np.sum(matrix[letter2idx[x0]][:])\n",
    "    return np.argmax(normalised)\n",
    "\n",
    "def arg_trivial_case(x0):\n",
    "    normalised = T[letter2idx[x0]]/np.sum(T[letter2idx[x0]][:])\n",
    "    return np.argmax(normalised)\n",
    "\n",
    "def generate_arg(st):\n",
    "    str = list(\".\"+st)\n",
    "    left=1\n",
    "    right=1\n",
    "    while left<len(str):\n",
    "        if(str[left]=='_'):\n",
    "            if  right<left:\n",
    "                right=left\n",
    "            while right<len(str) and str[right]=='_':\n",
    "                right+=1\n",
    "            if right<len(str):\n",
    "                str[left]=letterInv[arg_nontrivial_case(right-left,str[left-1],str[right])]\n",
    "            else:\n",
    "                str[left] = letterInv[arg_trivial_case(str[left-1])]\n",
    "        left+=1\n",
    "    return ''.join(str[1:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "therbr.tn.f.x.\n",
      "tutst.tn..toube.tnswere.\n",
      "in.ath.ta.hen...e.r.i.g\n",
      "qur.t.a.az.the.ht.th.the.th.\n"
     ]
    }
   ],
   "source": [
    "for i in test_strings:\n",
    "    print(generate_arg(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4\n",
    "Considering white spaces and other charecters we could implement better estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
