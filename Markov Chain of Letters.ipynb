{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Behiye Avcı\n",
    "\n",
    "I hereby declare that I observed the honour code of the university when preparing the homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Programming Homework 3\n",
    "\n",
    "In this exercise we model a string of text using a Markov(1) model. For simplicity we only consider letters 'a-z'. Capital letters 'A-Z' are mapped to the corresponding ones. All remaining letters, symbols, numbers, including spaces, are denoted by '.'.\n",
    "\n",
    "\n",
    "We have a probability table $T$ where $T_{i,j} = p(x_t = j | x_{t-1} = i)$  transition model of letters in English text for $t=1,2 \\dots N$. Assume that the initial letter in a string is always a space denoted as $x_0 = \\text{'.'}$. Such a model where the probability table is always the same is sometimes called a stationary model.\n",
    "\n",
    "1. For a given $N$, write a program to sample random strings with letters $x_1, x_2, \\dots, x_N$ from $p(x_{1:N}|x_0)$\n",
    "1. Now suppose you are given strings with missing letters, where each missing letter is denoted by a question mark (or underscore, as below). Implement a method, that samples missing letters conditioned on observed ones, i.e., samples from $p(x_{-\\alpha}|x_{\\alpha})$ where $\\alpha$ denotes indices of observed letters. For example, if the input is 't??.', we have $N=4$ and\n",
    "$x_1 = \\text{'t'}$ and $x_4 = \\text{'.'}$, $\\alpha=\\{1,4\\}$ and $-\\alpha=\\{2,3\\}$. Your program may possibly generate the strings 'the.', 'twi.', 'tee.', etc. Hint: make sure to make use all data given and sample from the correct distribution. Implement the method and print the results for the test strings below. \n",
    "1. Describe a method for filling in the gaps by estimating the most likely letter for each position. Hint: you need to compute\n",
    "$$\n",
    "x_{-\\alpha}^* = \\arg\\max_{x_{-\\alpha}} p(x_{-\\alpha}|x_{\\alpha})\n",
    "$$\n",
    "Implement the method and print the results for the following test strings along with the log-probability  $\\log p(x_{-\\alpha}^*,x_{\\alpha})$.\n",
    "1. Discuss how you can improve the model to get better estimations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_strings = ['th__br__n.f_x.', '_u_st__n_.to_be._nsw_r__','i__at_._a_h_n_._e_r_i_g','q___t.___z._____t.__.___.__.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: The code below loads a table of transition probabilities for English text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$p(x_t = \\text{'u'} | x_{t-1} = \\text{'q'})$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9949749\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$p(x_t | x_{t-1} = \\text{'a'})$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 0.0002835\n",
      "b 0.0228302\n",
      "c 0.0369041\n",
      "d 0.0426290\n",
      "e 0.0012216\n",
      "f 0.0075739\n",
      "g 0.0171385\n",
      "h 0.0014659\n",
      "i 0.0372661\n",
      "j 0.0002353\n",
      "k 0.0110124\n",
      "l 0.0778259\n",
      "m 0.0260757\n",
      "n 0.2145354\n",
      "o 0.0005459\n",
      "p 0.0195213\n",
      "q 0.0001749\n",
      "r 0.1104770\n",
      "s 0.0934290\n",
      "t 0.1317960\n",
      "u 0.0098029\n",
      "v 0.0306574\n",
      "w 0.0088799\n",
      "x 0.0009562\n",
      "y 0.0233701\n",
      "z 0.0018701\n",
      ". 0.0715219\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from IPython.display import display, Latex\n",
    "\n",
    "alphabet = [chr(i+ord('a')) for i in range(26)]\n",
    "alphabet.append('.')\n",
    "letter2idx = {c:i for i,c in enumerate(alphabet)}\n",
    "\n",
    "T = []\n",
    "with open('transitions.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        T.append(row)\n",
    "\n",
    "print('Example')\n",
    "## p(x_t = 'u' | x_{t-1} = 'q')\n",
    "display(Latex(r\"$p(x_t = \\text{'u'} | x_{t-1} = \\text{'q'})$\"))\n",
    "print(T[letter2idx['q']][letter2idx['u']])\n",
    "display(Latex(r\"$p(x_t | x_{t-1} = \\text{'a'})$\"))\n",
    "for c,p in zip(alphabet,T[letter2idx['a']]):\n",
    "    print(c,p)\n",
    "T=np.array(T)\n",
    "T=T.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 26,\n",
       " 'a': 0,\n",
       " 'b': 1,\n",
       " 'c': 2,\n",
       " 'd': 3,\n",
       " 'e': 4,\n",
       " 'f': 5,\n",
       " 'g': 6,\n",
       " 'h': 7,\n",
       " 'i': 8,\n",
       " 'j': 9,\n",
       " 'k': 10,\n",
       " 'l': 11,\n",
       " 'm': 12,\n",
       " 'n': 13,\n",
       " 'o': 14,\n",
       " 'p': 15,\n",
       " 'q': 16,\n",
       " 'r': 17,\n",
       " 's': 18,\n",
       " 't': 19,\n",
       " 'u': 20,\n",
       " 'v': 21,\n",
       " 'w': 22,\n",
       " 'x': 23,\n",
       " 'y': 24,\n",
       " 'z': 25}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letter2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def func1(N):\n",
    "    str = \".\"\n",
    "    for i in range(N):\n",
    "        idx = currentIndex(T[26]);\n",
    "        str = str + alphabet[idx]\n",
    "    return str;\n",
    "        \n",
    "def currentIndex(weights):\n",
    "    sum = 0;\n",
    "    x = np.random.random()\n",
    "    #print(x)\n",
    "    idx = 0\n",
    "    for w in weights:\n",
    "        sum = sum + w\n",
    "        #print(w)\n",
    "        if(x < sum):\n",
    "            return idx\n",
    "        else: \n",
    "            idx = idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".aatcp.jufshcq.taimwtceat.ag.ftb.cahaswghfuhffdttsahaspitemamsnfltiasessaipithmcc.dpwowbattmbrmulw.it\n"
     ]
    }
   ],
   "source": [
    "K = func1(100)\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-266-e527f97a37ff>, line 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-266-e527f97a37ff>\"\u001b[0;36m, line \u001b[0;32m30\u001b[0m\n\u001b[0;31m    idx = currentIndex(weights)\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "test_strings = ['th__br__n.f_x.', '_u_st__n_.to_be._nsw_r__','i__at_._a_h_n_._e_r_i_g','q___t.___z._____t.__.___.__.']\n",
    "def func2():\n",
    "    for i, str  in enumerate(test_strings):\n",
    "        for j, letter in enumerate(str):\n",
    "            if(letter == '_'):\n",
    "                result(i, j)\n",
    "    for str in test_strings:\n",
    "        print(str)\n",
    "\n",
    "def result(i,j):\n",
    "    l = 0\n",
    "    curr = test_strings[i][j]\n",
    "    first = test_strings[i][j-1]\n",
    "    if(j == 0):\n",
    "        first = '.'\n",
    "    while (curr == '_' and j + l < len(test_strings[i])-1):\n",
    "        l = l + 1\n",
    "        curr = test_strings[i][j + l]\n",
    "    if(j + l == len(test_strings[i])-1):\n",
    "        last = '.'\n",
    "    else:\n",
    "        last = test_strings[i][j + l]\n",
    "    \n",
    "    weights = 0;\n",
    "    beg=T[letter2idx[first]]\n",
    "    end=np.linalg.matrix_power(T,l).transpose()[letter2idx[last]]\n",
    "    weights=beg*end\n",
    "    weights/=np.sum(weights\n",
    "    \n",
    "                    idx = 0\n",
    "    idx = currentIndex(weights)\n",
    "    term = alphabet[idx]\n",
    "    test_strings[i] = test_strings[i][:j] + term + test_strings[i][j+1:]\n",
    "    \n",
    "def findVector(first, last, l):   \n",
    "    weights = 0;\n",
    "    beg=T[letter2idx[first]]\n",
    "    end=np.linalg.matrix_power(T,l).transpose()[letter2idx[last]]\n",
    "    weights=beg*end\n",
    "    weights/=np.sum(weights)\n",
    "    return currentIndex(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the.brrin.fux.\n",
      "aunsthine.to.be.answera.\n",
      "ingath.wathand.weareing\n",
      "qut.t..wiz.tsount.th.rig.on.\n"
     ]
    }
   ],
   "source": [
    "func2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result could be improved if the best model is found for the problem. We are using Markov(1) currently, however other markov models would work better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
