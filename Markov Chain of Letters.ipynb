{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Name: Çağatay Şahin\n",
    "I hereby declare that I observed the honour code of the university when preparing the homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_strings = ['th__br__n.f_x.', '_u_st__n_.to_be._nsw_r__','i__at_._a_h_n_._e_r_i_g','q___t.___z._____t.__.___.__.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$p(x_t = \\text{'u'} | x_{t-1} = \\text{'q'})$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9949749\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$p(x_t | x_{t-1} = \\text{'a'})$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 0.0002835\n",
      "b 0.0228302\n",
      "c 0.0369041\n",
      "d 0.0426290\n",
      "e 0.0012216\n",
      "f 0.0075739\n",
      "g 0.0171385\n",
      "h 0.0014659\n",
      "i 0.0372661\n",
      "j 0.0002353\n",
      "k 0.0110124\n",
      "l 0.0778259\n",
      "m 0.0260757\n",
      "n 0.2145354\n",
      "o 0.0005459\n",
      "p 0.0195213\n",
      "q 0.0001749\n",
      "r 0.1104770\n",
      "s 0.0934290\n",
      "t 0.1317960\n",
      "u 0.0098029\n",
      "v 0.0306574\n",
      "w 0.0088799\n",
      "x 0.0009562\n",
      "y 0.0233701\n",
      "z 0.0018701\n",
      ". 0.0715219\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from IPython.display import display, Latex\n",
    "\n",
    "alphabet = [chr(i+ord('a')) for i in range(26)]\n",
    "alphabet.append('.')\n",
    "letter2idx = {c:i for i,c in enumerate(alphabet)}\n",
    "\n",
    "T = []\n",
    "with open('transitions.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        T.append(row)\n",
    "\n",
    "print('Example')\n",
    "## p(x_t = 'u' | x_{t-1} = 'q')\n",
    "display(Latex(r\"$p(x_t = \\text{'u'} | x_{t-1} = \\text{'q'})$\"))\n",
    "print(T[letter2idx['q']][letter2idx['u']])\n",
    "display(Latex(r\"$p(x_t | x_{t-1} = \\text{'a'})$\"))\n",
    "for c,p in zip(alphabet,T[letter2idx['a']]):\n",
    "    print(c,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thoflghiloun.oruckealivata.ad.ershim.lathae.d.mayenis.p.s.avive.min.en.t.wallmsas.mesoritore.of.or.e.n.bstr.te.his.walldsomanome.curs.satre.mbundre.orth.h.ed.theaint.m..ch.thenousstw.whes.pe.buat.hesi.ngea.se.tevedirint.wnflaseired.woly.f.bn.t.wis.thast.t..inngeatr.f.qum.s..wether.abubit.e.arin.a.wo\n"
     ]
    }
   ],
   "source": [
    "import itertools as it\n",
    "import numpy as np\n",
    "\n",
    "def sample_string(N,T,numeric_alphabet):\n",
    "    \n",
    "    string_arr = np.zeros(N,dtype=np.str)\n",
    "    cur = letter2idx['.']\n",
    "\n",
    "    for i in range(N):\n",
    "        cur = np.random.choice(numeric_alphabet,p=T[cur])\n",
    "        string_arr[i] = alphabet[cur]\n",
    "    \n",
    "    print(''.join(string_arr))\n",
    "    \n",
    "\n",
    "#Normalizing each row\n",
    "T_norm = np.array(T)         \n",
    "T_norm = T_norm.astype(np.float)\n",
    "for i in range(len(alphabet)):\n",
    "    T_norm[i] = T_norm[i] / T_norm[i].sum()\n",
    "    \n",
    "numeric_alphabet = [x for x in range(len(alphabet))]\n",
    "\n",
    "sample_string(300,T_norm,numeric_alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each disjoint unknown substring will be called block. Since we use Markov(1) Model, each block is independent. \n",
    "Within a block we have $X_{1:N}$. $X_{0}$ is the letter just left to the first element of block and $X_{N+1}$ is the letter right after to the last element of block. $\\hat{x}_{0}$\n",
    "In general for each block we seek to sample \n",
    "\n",
    "$p(x_{-\\\\a}|x_{\\\\a})$ = $p(x_{1}|x_{0} = \\hat{x}_{0}) p(x_{2}|x_{1}) p(x_{3}|x_{2}) ... p(x_{N}|x_{N-1}) p({x}_{N+1} = \\hat{x}_{N+1}|x_{N}) $ \n",
    "due to Markov Property\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method for Part 2 & 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import numpy as np\n",
    "\n",
    "def predict(string,is_sample=True):\n",
    "    \n",
    "    chars = list(string)\n",
    "    string += '.'\n",
    "    cur_unknown = False\n",
    "    prev_unknown = False\n",
    "\n",
    "    blocks = []\n",
    "    for i in range(len(string)):\n",
    "        if string[i] == '_' or string[i] == '?':\n",
    "            cur_unknown = True\n",
    "        else:\n",
    "            cur_unknown = False\n",
    "        if prev_unknown == True and cur_unknown == True:\n",
    "            blocks[len(blocks)-1].append(i)\n",
    "        if prev_unknown == False and cur_unknown == True:\n",
    "            blocks.append([i])\n",
    "        prev_unknown = cur_unknown\n",
    "\n",
    "    #print(blocks)\n",
    "\n",
    "    blocks_extended = []\n",
    "\n",
    "    for block in blocks:\n",
    "        temp = [len(block)]\n",
    "        prev_index = block[0]-1 #index in string\n",
    "        next_index = block[len(block)-1]+1 #index in string\n",
    "        prev_index = letter2idx[string[prev_index]] #corresponding index in alphabet\n",
    "        next_index = letter2idx[string[next_index]] #corresponding index in alphabet\n",
    "        temp.extend([prev_index])\n",
    "        temp.extend([next_index])\n",
    "        blocks_extended.append(temp)\n",
    "\n",
    "    #print(blocks_extended) #Represents [len(block),prev_index, next_index] for each block\n",
    "\n",
    "    numeric_alphabet = [x for x in range(len(alphabet))]\n",
    "    \n",
    "    probability_all = 1\n",
    "    for block_index in range(len(blocks)):\n",
    "        block = blocks_extended[block_index]\n",
    "        cartesian=list(it.product(numeric_alphabet,repeat=block[0]))\n",
    "        probabilities = np.zeros(len(cartesian),dtype=float)\n",
    "\n",
    "        for tup_index in range(len(cartesian)):\n",
    "            tup = cartesian[tup_index];\n",
    "            product = float(T[block[1]][tup[0]]) # P(first_letter_of_block | prev_letter)\n",
    "            for index in range(0,len(tup)-1):\n",
    "                product*=float(T[tup[index]][tup[index+1]]) # Multiply probabilities of each transition in candidate block\n",
    "\n",
    "            product *= float(T[tup[len(tup)-1]][block[2]])  # P(next_letter | last_letter_of_block)\n",
    "            probabilities[tup_index] = product\n",
    "        \n",
    "        \n",
    "        probabilities /= probabilities.sum()\n",
    "        if is_sample: #for question part-2\n",
    "            selection=np.random.choice(np.arange(0,len(alphabet)**block[0]),p=probabilities)\n",
    "        else: #for question part-3\n",
    "            selection = np.argmax(probabilities)\n",
    "        \n",
    "        probability_all *= probabilities[selection]\n",
    "        \n",
    "        block = blocks[block_index]\n",
    "        block_selection = cartesian[selection]\n",
    "\n",
    "        for j in range(len(block)):\n",
    "            chars[block[j]] = alphabet[block_selection[j]]\n",
    "    \n",
    "    filled_string = ''.join(chars)\n",
    "   \n",
    "    print(filled_string)\n",
    "    if not is_sample:\n",
    "        print(np.log(probability_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tht.brdin.fex.\n",
      "thoubrman.fex.\n",
      "tho.br.an.fex.\n",
      "the.br.in.fex.\n",
      "\n",
      "quasthind.to.be.answarnd\n",
      "ounstorne.toybe.rnsware.\n",
      "tutsthano.to.be.onswarea\n",
      "bunststnd.toube.answir.s\n",
      "\n",
      "igrate.sathand.fe.rding\n",
      "ie.ate.tathent.beuruing\n",
      "illate.hathiny.teur.ing\n",
      "itwatl.bathen..tear.ing\n",
      "\n",
      "qutat.morz.thas.t..d.red.ms.\n",
      "qum.t.lsiz.urd.at.id.pes.th.\n",
      "qui.t.lozz.t.he.t.en.pan.de.\n",
      "qur.t.rerz.wrin.t.ts.ing..t.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for string in test_strings:\n",
    "    for i in range(4):\n",
    "        predict(string)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 - Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the.br.an.fex.\n",
      "-3.07433486577\n",
      "\n",
      "oursthend.to.be.answered\n",
      "-11.0693279723\n",
      "\n",
      "in.ath.wathend.he.r.ing\n",
      "-11.636089996\n",
      "\n",
      "qus.t.herz.thed.t.he.the.he.\n",
      "-21.1402671647\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for string in test_strings:\n",
    "    predict(string,is_sample=False)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In natural languages, punctuation marks and uppercase letters would determine the structure of a sentence.  \n",
    "Additionally, a letter in word has a relation with multiple previous letters and \n",
    "a word in a sentence has a relation with multiple previous words in a context.\n",
    "\n",
    "So, to improve our model we would introduce uppercase letters and various punctuation marks in our alphabet\n",
    "and define the transition probabilities of them as well.\n",
    "\n",
    "More importantly, we would use a higher-order Markov Chain (say order 3) to model the relation of a letter with more than one previous letter"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
