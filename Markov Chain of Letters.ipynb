{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Onur Poyraz 2016705069"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "I hereby declare that I observed the honour code of the university when preparing the homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Pr?gr?mm?ng?H?m?w?rk 3\n",
    "\n",
    "In this exercise we model a string of text using a Markov(1) model. For simplicity we only consider letters 'a-z'. Capital letters 'A-Z' are mapped to the corresponding ones. All remaining letters, symbols, numbers, including spaces, are denoted by '.'.\n",
    "\n",
    "\n",
    "We have a probability table $T$ where $T_{i,j} = p(x_t = j | x_{t-1} = i)$  transition model of letters in English text for $t=1,2 \\dots N$. Assume that the initial letter in a string is always a space denoted as $x_0 = \\text{'.'}$. Such a model where the probability table is always the same is sometimes called a stationary model.\n",
    "\n",
    "1. For a given $N$, write a program to sample random strings with letters $x_1, x_2, \\dots, x_N$ from $p(x_{1:N}|x_0)$\n",
    "1. Now suppose you are given strings with missing letters, where each missing letter is denoted by a question mark (or underscore, as below). Implement a method, that samples missing letters conditioned on observed ones, i.e., samples from $p(x_{-\\alpha}|x_{\\alpha})$ where $\\alpha$ denotes indices of observed letters. For example, if the input is 't??.', we have $N=4$ and\n",
    "$x_1 = \\text{'t'}$ and $x_4 = \\text{'.'}$, $\\alpha=\\{1,4\\}$ and $-\\alpha=\\{2,3\\}$. Your program may possibly generate the strings 'the.', 'twi.', 'tee.', etc. Hint: make sure to make use all data given and sample from the correct distribution. Implement the method and print the results for the test strings below. \n",
    "1. Describe a method for filling in the gaps by estimating the most likely letter for each position. Hint: you need to compute\n",
    "$$\n",
    "x_{-\\alpha}^* = \\arg\\max_{x_{-\\alpha}} p(x_{-\\alpha}|x_{\\alpha})\n",
    "$$\n",
    "Implement the method and print the results for the following test strings along with the log-probability  $\\log p(x_{-\\alpha}^*,x_{\\alpha})$.\n",
    "1. Discuss how you can improve the model to get better estimations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_strings = ['th__br__n.f_x.', '_u_st__n_.to_be._nsw_r__','i__at_._a_h_n_._e_r_i_g','q___t.___z._____t.__.___.__.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Hint: The code below loads a table of transition probabilities for English text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$p(x_t = \\text{'u'} | x_{t-1} = \\text{'q'})$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9949749\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$p(x_t | x_{t-1} = \\text{'a'})$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', '0.0002835')\n",
      "('b', '0.0228302')\n",
      "('c', '0.0369041')\n",
      "('d', '0.0426290')\n",
      "('e', '0.0012216')\n",
      "('f', '0.0075739')\n",
      "('g', '0.0171385')\n",
      "('h', '0.0014659')\n",
      "('i', '0.0372661')\n",
      "('j', '0.0002353')\n",
      "('k', '0.0110124')\n",
      "('l', '0.0778259')\n",
      "('m', '0.0260757')\n",
      "('n', '0.2145354')\n",
      "('o', '0.0005459')\n",
      "('p', '0.0195213')\n",
      "('q', '0.0001749')\n",
      "('r', '0.1104770')\n",
      "('s', '0.0934290')\n",
      "('t', '0.1317960')\n",
      "('u', '0.0098029')\n",
      "('v', '0.0306574')\n",
      "('w', '0.0088799')\n",
      "('x', '0.0009562')\n",
      "('y', '0.0233701')\n",
      "('z', '0.0018701')\n",
      "('.', '0.0715219')\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from IPython.display import display, Latex, Math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "alphabet = [chr(i+ord('a')) for i in range(26)]\n",
    "alphabet.append('.')\n",
    "letter2idx = {c:i for i,c in enumerate(alphabet)}\n",
    "\n",
    "T = []\n",
    "with open('transitions.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        T.append(row)\n",
    "\n",
    "print('Example')\n",
    "## p(x_t = 'u' | x_{t-1} = 'q')\n",
    "display(Latex(r\"$p(x_t = \\text{'u'} | x_{t-1} = \\text{'q'})$\"))\n",
    "print (T[letter2idx['q']][letter2idx['u']])\n",
    "display(Latex(r\"$p(x_t | x_{t-1} = \\text{'a'})$\"))\n",
    "for c,p in zip(alphabet,T[letter2idx['a']]):\n",
    "    print(c,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Firstly I took T lists as a matrix Data and I normalize the data because it is not completely normalised. (I see that some of the rows sum is not equal to 1 exactly. Some of them is equal to 1.01 and some of them are equals to 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "Data = np.loadtxt(\"transitions.txt\",dtype=float)\n",
    "Data = normalize(Data, axis=1, norm='l1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".t.f.te.mac.e.gs.ted.ifera.t.ay.ateeshurblan.lonurald.s.ad.hon.smios.atan.c.y.ods.f.st.as.d.t.nd.f.to\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "text='.'\n",
    "\n",
    "for k in range(N):\n",
    "    index=alphabet.index(text[k])\n",
    "    output = np.random.choice(alphabet,1, p=Data[index,:])\n",
    "    text=text+output.tostring()\n",
    "print text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In the below code I did not use posterior letters. I use them in second one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".thulbrohn.f.x.\n",
      ".tusstinnk.toube.rnswhrin\n",
      ".ie.atu.aaphtnd.eerreing\n",
      ".qucdt.misz.do.jut.or.c.s.wn.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_strings)):\n",
    "    text = ''\n",
    "    test = '.'\n",
    "    test = test + test_strings[i]\n",
    "    inp = np.array(list(test))\n",
    "    for j in range(len(inp)):\n",
    "        if inp[j]=='_':\n",
    "            last_letter = text[j-1]\n",
    "            #print last_letter\n",
    "            index=alphabet.index(last_letter)\n",
    "            output = np.random.choice(alphabet,1, p=Data[index,:])\n",
    "        else:\n",
    "            output = inp[j]\n",
    "        text = text+output.tostring()\n",
    "    print text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".thi.bre.n.fex..\n",
      "..uisthind.tombe.inswar.n.\n",
      ".iowate.hathing.searging.\n",
      ".qutit.atez.y.thet.w..mal.or..\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_strings)):\n",
    "    text = ''\n",
    "    test = '.'\n",
    "    test = test + test_strings[i] + test\n",
    "    inp = np.array(list(test))\n",
    "    for j in range(len(inp)):\n",
    "        if inp[j]=='_' and inp[j+1]=='_':\n",
    "            last_letter = text[j-1]\n",
    "            index=alphabet.index(last_letter)\n",
    "            output = np.random.choice(alphabet,1, p=Data[index,:])\n",
    "        elif inp[j]=='_' and inp[j+1]!='_':\n",
    "            last_letter = text[j-1]\n",
    "            index=alphabet.index(last_letter)\n",
    "            post = test[j+1]\n",
    "            i_post = alphabet.index(post)\n",
    "            new_prob = np.multiply(Data[index,:],Data[:,i_post].T)\n",
    "            summ = 0\n",
    "            for k in range(len(Data)):\n",
    "                summ =summ + new_prob[k]\n",
    "            output = np.random.choice(alphabet,1, p=new_prob/summ)\n",
    "        else:\n",
    "            output = inp[j]\n",
    "        text = text+output.tostring()\n",
    "    print text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".the.brean.fex..\n",
      ".oursthend.to.be.answered.\n",
      ".in.ath.wathend.he.r.ing.\n",
      ".qur.t.thiz.the.at.th.the.th..\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_strings)):\n",
    "    text = ''\n",
    "    test = '.'\n",
    "    test = test + test_strings[i] + test\n",
    "    inp = np.array(list(test))\n",
    "    for j in range(len(inp)):\n",
    "        if inp[j]=='_' and inp[j+1]=='_':\n",
    "            last_letter = text[j-1]\n",
    "            index=alphabet.index(last_letter)\n",
    "            choice = np.argmax(Data[index,:])\n",
    "            output = alphabet[choice]\n",
    "            output = np.array(output)\n",
    "        elif inp[j]=='_' and inp[j+1]!='_':\n",
    "            last_letter = text[j-1]\n",
    "            index=alphabet.index(last_letter)\n",
    "            post = test[j+1]\n",
    "            i_post = alphabet.index(post)\n",
    "            new_prob = np.multiply(Data[index,:],Data[:,i_post].T)\n",
    "            choice = np.argmax(new_prob)\n",
    "            output = alphabet[choice]\n",
    "            output = np.array(output)\n",
    "        else:\n",
    "            output = inp[j]\n",
    "        text = text+output.tostring()\n",
    "    print text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "I made a system which is well worked for one missed letters. However it is not well worked for more missed letters. Actually There could be better estimation algorithms for estimate them. Because I made estimation one by one however if we can update them all syncronously we can take better results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
