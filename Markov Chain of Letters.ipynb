{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Feyzullah Alim Kalyoncu\n",
    "\n",
    "2015751042\n",
    "\n",
    "I hereby declare that I observed the honour code of the university when preparing the homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Homework 3\n",
    "\n",
    "In this exercise we model a string of text using a Markov(1) model. For simplicity we only consider letters 'a-z'. Capital letters 'A-Z' are mapped to the corresponding ones. All remaining letters, symbols, numbers, including spaces, are denoted by '.'.\n",
    "\n",
    "\n",
    "We have a probability table $T$ where $T_{i,j} = p(x_t = j | x_{t-1} = i)$  transition model of letters in English text for $t=1,2 \\dots N$. Assume that the initial letter in a string is always a space denoted as $x_0 = \\text{'.'}$. Such a model where the probability table is always the same is sometimes called a stationary model.\n",
    "\n",
    "1. For a given $N$, write a program to sample random strings with letters $x_1, x_2, \\dots, x_N$ from $p(x_{1:N}|x_0)$\n",
    "1. Now suppose you are given strings with missing letters, where each missing letter is denoted by a question mark (or underscore, as below). Implement a method, that samples missing letters conditioned on observed ones, i.e., samples from $p(x_{-\\alpha}|x_{\\alpha})$ where $\\alpha$ denotes indices of observed letters. For example, if the input is 't??.', we have $N=4$ and\n",
    "$x_1 = \\text{'t'}$ and $x_4 = \\text{'.'}$, $\\alpha=\\{1,4\\}$ and $-\\alpha=\\{2,3\\}$. Your program may possibly generate the strings 'the.', 'twi.', 'tee.', etc. Hint: make sure to make use all data given and sample from the correct distribution. Implement the method and print the results for the test strings below. \n",
    "1. Describe a method for filling in the gaps by estimating the most likely letter for each position. Hint: you need to compute\n",
    "$$\n",
    "x_{-\\alpha}^* = \\arg\\max_{x_{-\\alpha}} p(x_{-\\alpha}|x_{\\alpha})\n",
    "$$\n",
    "Implement the method and print the results for the following test strings along with the log-probability  $\\log p(x_{-\\alpha}^*,x_{\\alpha})$.\n",
    "1. Discuss how you can improve the model to get better estimations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_strings = ['th__br__n.f_x.', '_u_st__n_.to_be._nsw_r__','i__at_._a_h_n_._e_r_i_g','q___t.___z._____t.__.___.__.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: The code below loads a table of transition probabilities for English text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$p(x_t = \\text{'u'} | x_{t-1} = \\text{'q'})$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9949749\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$p(x_t | x_{t-1} = \\text{'a'})$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', '0.0002835')\n",
      "('b', '0.0228302')\n",
      "('c', '0.0369041')\n",
      "('d', '0.0426290')\n",
      "('e', '0.0012216')\n",
      "('f', '0.0075739')\n",
      "('g', '0.0171385')\n",
      "('h', '0.0014659')\n",
      "('i', '0.0372661')\n",
      "('j', '0.0002353')\n",
      "('k', '0.0110124')\n",
      "('l', '0.0778259')\n",
      "('m', '0.0260757')\n",
      "('n', '0.2145354')\n",
      "('o', '0.0005459')\n",
      "('p', '0.0195213')\n",
      "('q', '0.0001749')\n",
      "('r', '0.1104770')\n",
      "('s', '0.0934290')\n",
      "('t', '0.1317960')\n",
      "('u', '0.0098029')\n",
      "('v', '0.0306574')\n",
      "('w', '0.0088799')\n",
      "('x', '0.0009562')\n",
      "('y', '0.0233701')\n",
      "('z', '0.0018701')\n",
      "('.', '0.0715219')\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from IPython.display import display, Latex\n",
    "\n",
    "alphabet = [chr(i+ord('a')) for i in range(26)]\n",
    "alphabet.append('.')\n",
    "letter2idx = {c:i for i,c in enumerate(alphabet)}\n",
    "\n",
    "T = []\n",
    "with open('transitions.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        T.append(row)\n",
    "\n",
    "print('Example')\n",
    "## p(x_t = 'u' | x_{t-1} = 'q')\n",
    "display(Latex(r\"$p(x_t = \\text{'u'} | x_{t-1} = \\text{'q'})$\"))\n",
    "print(T[letter2idx['q']][letter2idx['u']])\n",
    "display(Latex(r\"$p(x_t | x_{t-1} = \\text{'a'})$\"))\n",
    "for c,p in zip(alphabet,T[letter2idx['a']]):\n",
    "    print(c,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#inverse mapping of characters is generated to use \n",
    "inverse_map = dict((y,x) for x,y in letter2idx.iteritems())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#string list to numpy array conversion of transition matrix\n",
    "t = []\n",
    "letters = []\n",
    "for i in inverse_map:\n",
    "    letters.append(inverse_map[i])\n",
    "    t.append([float(i) for i in T[letter2idx[inverse_map[i]]]])\n",
    "transition = np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wread.ss.i\n"
     ]
    }
   ],
   "source": [
    "#Q1\n",
    "#For given N text is generated with using transition matrix\n",
    "N = 10\n",
    "#Starting letter is '.'\n",
    "prev_letter = '.'\n",
    "generated_str = []\n",
    "for i in range(0,N):\n",
    "    prev_letter = np.random.choice(letters,1, p = transition[letter2idx[prev_letter]] / np.sum(transition[letter2idx[prev_letter]]) )[0]\n",
    "    generated_str.append(prev_letter)\n",
    "print ''.join(generated_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$x_{0} -> x_{1} -> x_{2} -> ........ -> x_{N} -> x_{N+1}$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$We\\hspace{0.05cm}know\\hspace{0.1cm}x_{0}\\hspace{0.05cm}and\\hspace{0.1cm}x_{N+1}\\hspace{0.1cm}and\\hspace{0.1cm}we\\hspace{0.1cm}are\\hspace{0.1cm}trying\\hspace{0.1cm}to\\hspace{0.1cm}estimate\\hspace{0.1cm}the\\hspace{0.1cm}characters\\hspace{0.1cm}between\\hspace{0.1cm}them$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$p(x_{1:N}  | x_0 = \\widehat{x}_0, x_{N+1} = \\widehat{x}_{N+1}) \\propto$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$p(x_{N+1} = \\widehat{x}_{N+1} | x_N,  x_0 = \\widehat{x}_0)\\hspace{0.1cm}\\times\\hspace{0.1cm}p(x_{N} | x_{N-1},  x_0 = \\widehat{x}_0)\\hspace{0.1cm}\\times\\hspace{0.1cm}\\dots\\hspace{0.1cm}\\times\\hspace{0.1cm}p(x_{2} | x_{1},  x_0 = \\widehat{x}_0)\\hspace{0.1cm}\\times\\hspace{0.1cm}p(x_{1} | x_0 = \\widehat{x}_0) =$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$p(x_{N+1} = \\widehat{x}_{N+1} | x_N) \\hspace{0.1cm}\\times\\hspace{0.1cm} p(x_{N} | x_{N-1}) \\hspace{0.1cm}\\times\\hspace{0.1cm}\\dots\\hspace{0.1cm}\\times\\hspace{0.1cm}p(x_{2} | x_{1}) \\hspace{0.1cm}\\times\\hspace{0.1cm} p(x_{1} | x_0 = \\widehat{x}_0)$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Latex(r\"$x_{0} -> x_{1} -> x_{2} -> ........ -> x_{N} -> x_{N+1}$\") ) \n",
    "display(Latex(r\"$We\\hspace{0.05cm}know\\hspace{0.1cm}x_{0}\\hspace{0.05cm}and\\hspace{0.1cm}x_{N+1}\\hspace{0.1cm}and\\hspace{0.1cm}we\\hspace{0.1cm}are\\hspace{0.1cm}trying\\hspace{0.1cm}to\\hspace{0.1cm}estimate\\hspace{0.1cm}the\\hspace{0.1cm}characters\\hspace{0.1cm}between\\hspace{0.1cm}them$\"))\n",
    "display(Latex(r\"$p(x_{1:N}  | x_0 = \\widehat{x}_0, x_{N+1} = \\widehat{x}_{N+1}) \\propto$\") ) \n",
    "display(Latex(r\"$p(x_{N+1} = \\widehat{x}_{N+1} | x_N,  x_0 = \\widehat{x}_0)\\hspace{0.1cm}\\times\\hspace{0.1cm}p(x_{N} | x_{N-1},  x_0 = \\widehat{x}_0)\\hspace{0.1cm}\\times\\hspace{0.1cm}\\dots\\hspace{0.1cm}\\times\\hspace{0.1cm}p(x_{2} | x_{1},  x_0 = \\widehat{x}_0)\\hspace{0.1cm}\\times\\hspace{0.1cm}p(x_{1} | x_0 = \\widehat{x}_0) =$\") )\n",
    "display(Latex(r\"$p(x_{N+1} = \\widehat{x}_{N+1} | x_N) \\hspace{0.1cm}\\times\\hspace{0.1cm} p(x_{N} | x_{N-1}) \\hspace{0.1cm}\\times\\hspace{0.1cm}\\dots\\hspace{0.1cm}\\times\\hspace{0.1cm}p(x_{2} | x_{1}) \\hspace{0.1cm}\\times\\hspace{0.1cm} p(x_{1} | x_0 = \\widehat{x}_0)$\") ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['th__br__n.f_x.',\n",
       " '_u_st__n_.to_be._nsw_r__',\n",
       " 'i__at_._a_h_n_._e_r_i_g',\n",
       " 'q___t.___z._____t.__.___.__.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theabrcon.fex.\n",
      "ourstlond.toube.answar.t\n",
      "ig.ate..athenm.te.raing\n",
      "qur.t..cez.th.t.t.wh.y.e.rf.\n"
     ]
    }
   ],
   "source": [
    "for string in test_strings:\n",
    "    prev_index = -1\n",
    "    prev_letter = '.'\n",
    "    str_list = list(string)\n",
    "    # '.' is added to the end of the given sequence\n",
    "    str_list.append('.')\n",
    "    for idx, letter in enumerate(str_list):\n",
    "        if letter == '_':\n",
    "            #previous character and its index is found here\n",
    "            for i in range(idx-1,-1,-1):\n",
    "                if str_list[i] != '_':\n",
    "                    prev_index = i\n",
    "                    prev_letter = str_list[i]\n",
    "                    break\n",
    "            #next character and its index is found here\n",
    "            for i in range(idx,len(str_list),+1):\n",
    "                if str_list[i] != '_':\n",
    "                    next_index = i\n",
    "                    next_letter = str_list[i]\n",
    "                    break\n",
    "            # power is the power of the transition matrix that we need to find\n",
    "            # as in the derivation given above, the next letter-row of powered matrix represents the part from x_N+1 to x_1\n",
    "            power = next_index - prev_index -1\n",
    "            powered = LA.matrix_power(transition, power)\n",
    "            #multiplying prev letter column of transition matrix with calculated row of powered matrix gives us our final probabilities\n",
    "            choices = np.multiply(transition[letter2idx[prev_letter]], powered[:,letter2idx[next_letter]])\n",
    "            choices = choices / np.sum(choices)\n",
    "            #character for given index is randomly chooses\n",
    "            str_list[idx] = np.random.choice(letters,1, p = choices)[0]\n",
    "        \n",
    "    print ''.join(str_list[0:len(str_list)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.33516666773\n",
      "the.br.an.fex.\n",
      "-6.14251472448\n",
      "oursthend.to.be.answered\n",
      "-11.1960044007\n",
      "in.ath.wathend.he.r.ing\n",
      "-21.15161581\n",
      "qur.t.thiz.the.at.an.the.an.\n"
     ]
    }
   ],
   "source": [
    "prob = 0\n",
    "for string in test_strings:\n",
    "    prev_index = -1\n",
    "    prev_letter = '.'\n",
    "    str_list = list(string)\n",
    "    str_list.append('.')\n",
    "    for idx, letter in enumerate(str_list):\n",
    "        if letter == '_':\n",
    "            \n",
    "            for i in range(idx-1,-1,-1):\n",
    "                if str_list[i] != '_':\n",
    "                    prev_index = i\n",
    "                    prev_letter = str_list[i]\n",
    "                    break\n",
    "            \n",
    "            for i in range(idx,len(str_list),+1):\n",
    "                if str_list[i] != '_':\n",
    "                    next_index = i\n",
    "                    next_letter = str_list[i]\n",
    "                    break\n",
    "                    \n",
    "            power = next_index - prev_index -1\n",
    "            powered = LA.matrix_power(transition, power)\n",
    "            choices = np.multiply(transition[letter2idx[prev_letter]], powered[:,letter2idx[next_letter]])\n",
    "            choices = choices / np.sum(choices)\n",
    "            #everthing until this point is the same as above\n",
    "            #here we take the argmax of probabilities array\n",
    "            #this gives us the most possible sequence\n",
    "            str_list[idx] = letters[np.argmax(choices)]\n",
    "            #log of character probabilites added to find the probability of the maximum sequence\n",
    "            prob += math.log10(choices[np.argmax(choices)])\n",
    "    #log10 probability of most probable string\n",
    "    print prob \n",
    "    print ''.join(str_list[0:len(str_list)-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q4\n",
    "We may get better results and more readable strings if we consider all of the given characters while estimating a gap.\n",
    "However, this may also distort the results. The best way to find the most possible and logical strings is that\n",
    "we should use words instead of characters (transition matrix is given for characters) to find most probable string. If we have a dictionary with given probabilities, we can estimate the words between two dots. Probabilities in this dictionary is like the transition matrix we have but it has words instead of characters. In this way, we can create a model that always finds a logical string which fits into the given charters and gaps"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
