{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Deniz Ekiz\n",
    "\n",
    "ID: 2016700051\n",
    "\n",
    "## Homework 3 Programming Part\n",
    "\n",
    "### Question\n",
    "In this exercise we model a string of text using a Markov(1) model. For simplicity we only consider\n",
    "letters ’a-z’. Capital letters ’A-Z’ are mapped to the corresponding ones. All remaining letters,\n",
    "symbols, numbers, including spaces, are denoted by ’.’.\n",
    "We have a probability table T where Ti,j = p(xt = j|xt−1 = i) transition model of letters in\n",
    "English text for t = 1, 2 . . . N. Assume that the initial letter in a string is always a space denoted\n",
    "as x0 = ’.’. Such a model where the probability table is always the same is sometimes called a\n",
    "stationary model.\n",
    "\n",
    "\n",
    "4. Discuss how you can improve the model to get better estimations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_strings = ['th__br__n.f_x.', '_u_st__n_.to_be._nsw_r__','i__at_._a_h_n_._e_r_i_g','q___t.___z._____t.__.___.__.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: The code below loads a table of transition probabilities for English text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$p(x_t = \\text{'u'} | x_{t-1} = \\text{'q'})$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9949749\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$p(x_t | x_{t-1} = \\text{'a'})$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', '0.0002835')\n",
      "('b', '0.0228302')\n",
      "('c', '0.0369041')\n",
      "('d', '0.0426290')\n",
      "('e', '0.0012216')\n",
      "('f', '0.0075739')\n",
      "('g', '0.0171385')\n",
      "('h', '0.0014659')\n",
      "('i', '0.0372661')\n",
      "('j', '0.0002353')\n",
      "('k', '0.0110124')\n",
      "('l', '0.0778259')\n",
      "('m', '0.0260757')\n",
      "('n', '0.2145354')\n",
      "('o', '0.0005459')\n",
      "('p', '0.0195213')\n",
      "('q', '0.0001749')\n",
      "('r', '0.1104770')\n",
      "('s', '0.0934290')\n",
      "('t', '0.1317960')\n",
      "('u', '0.0098029')\n",
      "('v', '0.0306574')\n",
      "('w', '0.0088799')\n",
      "('x', '0.0009562')\n",
      "('y', '0.0233701')\n",
      "('z', '0.0018701')\n",
      "('.', '0.0715219')\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from IPython.display import display, Latex\n",
    "\n",
    "alphabet = [chr(i+ord('a')) for i in range(26)]\n",
    "alphabet.append('.')\n",
    "letter2idx = {c:i for i,c in enumerate(alphabet)}\n",
    "\n",
    "T = []\n",
    "with open('transitions.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        T.append(row)\n",
    "\n",
    "print('Example')\n",
    "## p(x_t = 'u' | x_{t-1} = 'q')\n",
    "display(Latex(r\"$p(x_t = \\text{'u'} | x_{t-1} = \\text{'q'})$\"))\n",
    "print(T[letter2idx['q']][letter2idx['u']])\n",
    "display(Latex(r\"$p(x_t | x_{t-1} = \\text{'a'})$\"))\n",
    "t = 0.0\n",
    "for c,p in zip(alphabet,T[letter2idx['a']]):\n",
    "    print(c,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    " For a given N, write a program to sample random strings with letters x1, x2, . . . , xN from p(x1:N|x0)\n",
    "\n",
    "For N = 1 it is trivial. We will just need to select the corresponding section of conditional probability table.  Then make a random choice using np.random.choice function or argmax function.\n",
    "\n",
    "$p(x_1|x_0 = \\text{'.'})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['w']\n"
     ]
    }
   ],
   "source": [
    "N = 1\n",
    "#convert the string matrix to float. This is one time operation. Otherwise, we cant make calculations.\n",
    "T = [[float(y) for y in x] for x in T]\n",
    "# Assign first column of conditional probability table to a variable called guess_table\n",
    "#letter2idx is key-value pair. It stores the corresponding value for each letter.\n",
    "#Ex: letter2idx['a'] -> 0\n",
    "#  letter2idx['b'] -> 1 , letter2idx['.'] -> 26\n",
    "guess_table = T[letter2idx['.']]\n",
    "print(np.random.choice(alphabet,1,p=guess_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We need to find what is $p(x_{1:N} | x_0)$\n",
    "\n",
    "$p(x_{1:N} | x_0=\\text{'.'})=\\sum_{x_1,x_2,....,X_N}p(x_1|x_0 = \\text{'.'})p(x_2|x_1)p(x_3|x_2)...p(x_{N}|x_{N-1}) $\n",
    "\n",
    "We start selecting letter by letter we need to update the table each time.\n",
    "\n",
    "\n",
    "Given x_0 = '.', 27X27 conditional probability table T and number of letters N.\n",
    "\n",
    "Output, guess_table -> 27xN probability table which contains every probability of states x1 x2, ... xn with respect to letters\n",
    "However, when we decide to likelihood function. We need to update each probability,\n",
    "\n",
    "Algorithm should be, \n",
    "\n",
    "i = 0\n",
    "\n",
    "Start with p(x1|x_0 ='.'), make your guess with respect to likelihood function. Then, update next tables.\n",
    "\n",
    "return strings\n",
    "\n",
    "For this case it is also trivial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d n o p p x x e h c x e k a m a i d i f . u q x e d e r o k i l u q x e v x i d n o n o p a h c . r t s a p p y m h . e v e v l p p x x e b . o h c x x e r o s b . g . k c o d a g . g . y a e . d v o t p x e b b u q a w a z z z z z g n i r e h t i n e b b . y b a z z z z z z z u q x e b a z z z z r f o i p x x e r p s . h w o g o p o l a w o z u q o s k s y r e u q x x i a w e v d n a z a g n a v o z z z r b . y b u q x x e v i l b o j b u j t l u b y a m . y l l i p x e x x e u m r e n y z z z a h c n e i l a r e d e z z z r u q x e z z u o h c i w o s u q i p x e s u q c u q n a h g n i p e f e p m i f o j n k a z z r u q c x i v a g n a f o j e h w . g a m u q e r u q e v i b o . e l l l a . c s e b u q x x e v o n i g . g u q c c x x a w o l l u q . y a z a j b . a h . d n i l a . k c u q e s s l i w . s u q s t k c x e d e f o v o i x o r u q . d n o m a d n k n o i e w o t s e r f f u q x x i h t y b i w o m e r e t u q x x x x x i f o j b . s u j b . d n k n e c x e b o p m . d a z u j b . e v u q x e b a f o r u q u q e k a l p m o o b m a t . h c x e e n i z z z z z z z z z z i m o p x e z r u j n a . y k c x x e v . n w . y r a z r b . k c e h w e h t c x e m g i x i x i l i b m l b . t x e c . o c u b i m o f f n o c c c e g n w n k c e k o n i . f e b a d r a z z r i m u j b u q s d z i l n a . t a g n a z u q c x e m o t . g n k . r f o n i w . g n i x x x x a b u q s w o c x x x e k c x x e i c x e w o i a w o j n i w . w o j n o y l b u q e b m l u j b a m o f m i g n u q x x e z z z z o y b i v i l l l e h t x x x x x e h . d n a z z z z z z z z i u j b r b a z e m u q . y l l p x x e l d e t . z z r e v o l a z z r u j b . f o b u j e c x e r w . i c r m e h g u o . s i d n i x e p x x a w p x x x i v e w o i y n . . f o c i u p m l l b . m u b a z z z o w . p x x x e z z z z z z u q . g r p x x x i c e s n i s s k l c i z i v o m o j b m o p x x e k c u q n r f . k a m a c a z z r f o c u o d n o f i v i m . a v e j e c u q . r e l f f i . e v x e\n"
     ]
    }
   ],
   "source": [
    "#given N\n",
    "#create CDF\n",
    "sn = 10\n",
    "selection = 26 #string index in alphabet\n",
    "def string_generator(selection,sn):\n",
    "    N = 27\n",
    "    selected_strings = np.zeros([0,1])\n",
    "    for z in range(0,sn):\n",
    "        CDF = np.zeros((0,2))\n",
    "        my_sum = 0.0\n",
    "        prev_let = alphabet[selection]\n",
    "        for i in range(0,N):\n",
    "            #my_str = \"$p(x_t = \\text{'\" + alphabet[i]+ \"'} | x_{t-1} = \\text{'.'}$ ) = \"+ T[i][letter2idx[prev_let]] \n",
    "            #display( Latex(r\"$p(x_t = \\text{'\" + alphabet[i]+ r\"'} | x_{t-1} = \\text{'\"+prev_let+r\"'}$ ) = \"+ T[i][letter2idx[prev_let]] ))\n",
    "            CDF = np.vstack((CDF,[alphabet[i],float(T[i][letter2idx[prev_let]]) ]))\n",
    "            my_sum += float(T[i][letter2idx[prev_let]])\n",
    "        #print(my_sum)\n",
    "        # normalize and find CDF\n",
    "        CDF[0,1] = float(CDF[0,1])/my_sum\n",
    "        for i in range(1,N):\n",
    "            if(len(CDF[:,1])>1):\n",
    "                CDF[i,1] =  float(CDF[i,1])/my_sum  + float(CDF[i-1,1])\n",
    "            else:\n",
    "                CDF[0,1] = 1\n",
    "\n",
    "\n",
    "        #print(CDF)\n",
    "        s = np.random.uniform(0,1,1)\n",
    "        for i in range(0,len(s)):\n",
    "            for j in range(0,len(CDF[:,1])):\n",
    "                if(s[i] <= float(CDF[j,1])):\n",
    "                    selected_strings = np.vstack((selected_strings,CDF[j,0]))\n",
    "                    selection = j\n",
    "                    break\n",
    "    #print(\"For N= \"+ str(N) +\" and Sample number= \"+ str(sn) +\" Selected strings:\")\n",
    "    return selected_strings\n",
    "\n",
    "#Select your N \n",
    "N = 1000\n",
    "gens = string_generator(letter2idx['.'],N)\n",
    "for i in range(0,len(gens)):\n",
    "    print(str(gens[i,0])),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "Question: Now suppose you are given strings with missing letters, where each missing letter is denoted\n",
    "by a question mark (or underscore, as below). Implement a method, that samples missing\n",
    "letters conditioned on observed ones, i.e., samples from p(x−α|xα) where α denotes indices\n",
    "of observed letters. For example, if the input is ’t??.’, we have N = 4 and x1 = ’t’ and\n",
    "x4 = ’.’, α = {1, 4} and −α = {2, 3}. Your program may possibly generate the strings ’the.’,\n",
    "’twi.’, ’tee.’, etc. Hint: make sure to make use all data given and sample from the correct\n",
    "distribution. Implement the method and print the results for the test strings below.\n",
    "\n",
    "We have sucessfully generated our forward markov(1) model. Now let's turn it into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "t c c o  \n",
      "t c s u  \n",
      "t s r o  \n",
      "t o v o  \n",
      "t r f f  \n",
      "t a m o  \n",
      "t u b .  \n",
      "t x x x  \n",
      "t u q .  \n",
      "t c a f\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    print(\" \")\n",
    "    gens = string_generator(letter2idx['t'],3)\n",
    "    print('t'),\n",
    "    for i in range(0,len(gens)):\n",
    "        print(str(gens[i,0])),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toni\n",
      "t.me\n",
      "tush\n",
      "tthe\n",
      "t.be\n",
      "tha.\n",
      "toba\n",
      "tthe\n",
      "t.ch\n",
      "t.ho\n"
     ]
    }
   ],
   "source": [
    "def straight_markov(first_char,N,T,repeat,start,p,l):\n",
    "    #27xN shaped matrix\n",
    "    # given j  z\n",
    "    guess_table = np.zeros((27,N+2))\n",
    "    x_0 = first_char\n",
    "    x_prev = x_0\n",
    "    #fill guess_table\n",
    "    word = first_char\n",
    "    for j in range(0,N):\n",
    "        for i in range(0,len(alphabet)):\n",
    "            guess_table[i,0] = T[letter2idx[x_prev]][i]\n",
    "        #normalize\n",
    "        guess_table[:,0] = np.divide(guess_table[:,0],np.sum(guess_table[:,0]))\n",
    "        if not l:\n",
    "            x_prev = str(np.random.choice(alphabet,1,p = guess_table[:,0])[0])\n",
    "            word = np.vstack((word ,x_prev))\n",
    "        else:\n",
    "            x_prev = str(alphabet[np.argmax(guess_table[:,0])])\n",
    "            word = np.vstack((word ,x_prev))\n",
    "    if p :\n",
    "        print(''.join(word[start:,0]))\n",
    "    else:\n",
    "        return word[start:]\n",
    "for i in range(0,10):\n",
    "    straight_markov('t',3,T,10,0,p=True,l=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The markov model is like x0 -> x1 -> x2-> .... xn -> xn+1\n",
    "\n",
    "Let's look at for a _ _ b for getting some intuition. This model is p(x2,x3|x1=a,x4=b). We need to construct our table using these facts.\n",
    "\n",
    "$p(x_2,x_3|x_1=\\text{'a'}, x_4=b)$ $\\alpha$ $p(x_4=\\text{'b'},x_3,x_2,x_1=\\text{'a'}) $\n",
    "\n",
    "$=p(x_4=\\text{'b'}|x_3,x_2,x_1=\\text{'a'})p(x_3,x_2,x_1=\\text{'a'}) $\n",
    "\n",
    "$=p(x_4=\\text{'b'}|x_3,x_2,x_1='a')p(x_3|x_2,x_1='a')p(x_2,x_1='a')$\n",
    "\n",
    "$=p(x_4=\\text{'b'}|x_3,x_2,x_1=\\text{'a'})p(x_3|x_2,x_1=\\text{'a'})p(x_2|x_1=\\text{'a'})p(x_1=\\text{'a'}|x_o = \\text{'.'})$\n",
    "\n",
    "There is also x0 = '.' in this model, since we know that x0 = '.' \n",
    "\n",
    "p(x0 = '.') = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Applying conditional independences the equation turns out to be,\n",
    "\n",
    "$= p(x_4=\\text{'b'}|x_3)p(x_3|x_2)p(x_2|x_1 = \\text{'a'})p(x_1 = \\text{'a'}|x_0 = \\text{'.'})$\n",
    "\n",
    "$p(x_1 = 'a'|x_0 ='.')$ is a scalar.\n",
    "\n",
    "$p(x_2|x_1=\\text{'a'})$ is vector.\n",
    "\n",
    "$p(x_3|x_2)$ is our probability table T.\n",
    "\n",
    "$p(x4=\\text{'b'}|x3)$ is a vector.\n",
    "\n",
    "The result should be a vector of 27x1, where the row indexes are the elements of domain. Column is the unkown variables.\n",
    "\n",
    "This vector will be updated in every iteration, by adding the previous letter. New probabilities will be computed with respect to selected letter.\n",
    "\n",
    "We need to compute it in a automatic way\n",
    "\n",
    "The inference from future is not as trivial as forward inference.\n",
    "\n",
    "There are two types of string pattern one is a... case. \n",
    "\n",
    "The other is a..b case. There is no such other case only the number of unkowns are changing.\n",
    "\n",
    "I will identify the types of the strings with a function\n",
    "\n",
    "For general case we can prove it with the following:\n",
    "\n",
    "\n",
    "$ p(x_{1:N}|,x_0=\\hat{x_0})$\n",
    "\n",
    "$\\alpha$\n",
    "\n",
    "$p(x_{N+1}=\\hat{x}_{N+1}|x_N)p(x_n|x_{n-1})\\dots p(x_1|x_0=\\hat{x}_0)$\n",
    "\n",
    "The $p(x_1|x_0=\\hat{x}_0)$ term can be obtained easily via row selection.\n",
    "\n",
    "In order to obtain other terms we need to multiply T by N times. \n",
    "\n",
    "Then we need to take the transpoze of T.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "########### Inference from Future START ###########  \n",
    "def inference_from_future(first_char,last_char,N,T,start,l):\n",
    "    prob = 1\n",
    "    guess_table = np.zeros((27,N+2))\n",
    "    x_0 = first_char\n",
    "    x_prev = x_0\n",
    "    word = np.zeros((0,1))\n",
    "    #print(\"We have \" + str(N) + \" unkown \")\n",
    "    if(first_char == \"\"):\n",
    "        first_char = '.'\n",
    "    #print(\"x_1\"+ \" = \" + first_char)\n",
    "    #print(\"x_\"+str(N+1)+ \" = \" + last_char)\n",
    "    word = np.zeros((0,N))\n",
    "    word = np.vstack(first_char)\n",
    "    for i in range(0,N):\n",
    "        matrix = T\n",
    "        for x_d in alphabet:\n",
    "            #print(\"x_\"+str(i + 2)+\" = \" + x_d ),\n",
    "            guess_table[letter2idx[x_d],i] = T[letter2idx[first_char]][letter2idx[x_d]]\n",
    "        #if l and i == 0:\n",
    "            #for x_d in alphabet:\n",
    "                #print(\"x_\"+str(i + 2)+\" = \" + x_d ),\n",
    "                #guess_table[letter2idx[x_d],i] = guess_table[letter2idx[x_d],i-1]\n",
    "        #for j in range(0,N):\n",
    "        if l:\n",
    "            matrix=np.transpose(np.linalg.matrix_power(T,N-i)) # decrease the number of N since we pretend like we have found the letter\n",
    "        else:\n",
    "            matrix=np.transpose(np.linalg.matrix_power(T,N))\n",
    "        guess_table[:,i] = matrix[letter2idx[last_char]]*guess_table[:,i]\n",
    "        guess_table[:,i] = np.divide(guess_table[:,i],np.sum(guess_table[:,i]))\n",
    "        if l:\n",
    "            first_char = str(alphabet[np.argmax(guess_table[:,i])])\n",
    "            prob = np.dot(prob,guess_table[letter2idx[first_char],i])\n",
    "            # assign argmax as first char.\n",
    "        else:\n",
    "            first_char = str(np.random.choice(alphabet,1,p = guess_table[:,i])[0])\n",
    "            word = np.vstack((word ,first_char)) \n",
    "        repeat = 1\n",
    "    for i in range(0,repeat):\n",
    "        for j in range(0,N):\n",
    "            #if not l:\n",
    "                #word = np.vstack((word ,str(np.random.choice(alphabet,1,p = guess_table[:,j])[0]))) \n",
    "            #if l:\n",
    "                #print np.argmax(guess_table[:,j])\n",
    "                word = np.vstack((word ,str(alphabet[np.argmax(guess_table[:,j])])))\n",
    "        else:\n",
    "            if not l:\n",
    "                return word[start:]\n",
    "            if l:\n",
    "                return word[start:],prob\n",
    "    \n",
    "########### Inference from Future END ###########  \n",
    "########### STRING OPERATION FUNCTIONS START ###########  \n",
    "def underscore_finder(my_str):\n",
    "    list_of_underscore_indices = []\n",
    "    for i in range(0,len(my_str)):\n",
    "        if(my_str[i] == \"_\"):\n",
    "            list_of_underscore_indices.append(i)\n",
    "    return list_of_underscore_indices\n",
    "def group_problems(list_of_underscore_indices):\n",
    "    problems = []\n",
    "    for i in range(0,len(list_of_underscore_indices)):\n",
    "        problems.append([])\n",
    "    #print(problems)\n",
    "    z = 0\n",
    "    for i in range(0,len(list_of_underscore_indices)):\n",
    "        problems[z].append(list_of_underscore_indices[i])\n",
    "        if(i == len(list_of_underscore_indices)-1):\n",
    "            break\n",
    "        if(list_of_underscore_indices[i + 1] - list_of_underscore_indices[i] !=  1):\n",
    "            z = z + 1\n",
    "    #delete empty lists\n",
    "    return [x for x in problems if x != []]\n",
    "            \n",
    "    \n",
    "def problem_identify(my_str,list_of_underscore_indices,T,l):\n",
    "    str_len = len(my_str)\n",
    "    problems = group_problems(list_of_underscore_indices)\n",
    "    #print(problems)\n",
    "    p_num = len(problems)\n",
    "    pb = 1\n",
    "    #print(\"The amount of problem is : \" + str(p_num))\n",
    "    for i in range(0,p_num):\n",
    "        p_type = 0\n",
    "        #p_type = 1 if straight markov\n",
    "        #p_type = 2 if inference from future is need\n",
    "        #print(\"Working on problem no: \"+ str(i))\n",
    "        problem = problems[i]\n",
    "        if(problem[0] == 0):\n",
    "            prev = \"\"\n",
    "        else:\n",
    "            prev = my_str[problem[0]-1]\n",
    "        if(problem[-1] == (len(my_str) -1) ):\n",
    "            next_letter = \"\"\n",
    "            p_type = 1\n",
    "        else:\n",
    "            next_letter = my_str[problem[-1]+1]\n",
    "            p_type = 2\n",
    "        #print \"type = \", str(p_type),prev,len(problem)*\"_\",next_letter, \" length \",len(problem)\n",
    "        if not l:\n",
    "            my_str = inference(p_type,my_str,problem,prev,next_letter,T,l)\n",
    "        else:\n",
    "            my_str,prob = inference(p_type,my_str,problem,prev,next_letter,T,l)\n",
    "            pb = np.dot(prob,pb)\n",
    "    if l:\n",
    "        print \"Log prob:\", np.log(pb)\n",
    "    return my_str\n",
    "########### STRING OPERATION FUNCTIONS END ########### \n",
    "\n",
    "def inference(p_type,my_str,indices,prev_letter,next_letter,T,l):\n",
    "    prob = 1\n",
    "    if(my_str == \"\"):\n",
    "        #print(\"Null string error\")\n",
    "        return \"\"\n",
    "    if(p_type == 1):\n",
    "        #Straight markov\n",
    "        #print(\"Problem type = 1\")\n",
    "        if prev_letter == \"\":\n",
    "            result = straight_markov(first_char=\".\",T=T,N=len(indices),repeat=1,start=1,p=False,l=l)\n",
    "            #print(\"Straight! 1\")\n",
    "            #print(result)\n",
    "            a = 0\n",
    "            for i in indices:\n",
    "                list1 = list(my_str)\n",
    "                list1[i] = str(\"\".join(result[a]))\n",
    "                a = a+1\n",
    "                my_str = \"\".join(list1)\n",
    "            #print \"Result is \", my_str\n",
    "        else:\n",
    "            result = straight_markov(first_char=prev_letter,T=T,N=len(indices),repeat=1,start=1,p=False,l=l)\n",
    "            #print(\"Straight! 2\")\n",
    "            #print(result)\n",
    "            a = 0\n",
    "            for i in indices:\n",
    "                list1 = list(my_str)\n",
    "                list1[i] = str(\"\".join(result[a]))\n",
    "                a = a+1\n",
    "                my_str = \"\".join(list1)\n",
    "            #print \"Result is \", my_str\n",
    "    elif(p_type == 2):\n",
    "        if l:\n",
    "            result,pb = inference_from_future(first_char = prev_letter,last_char = next_letter,N=len(indices),T=T,start = 1,l=l)\n",
    "            prob = np.dot(pb,prob)\n",
    "        else:\n",
    "            result = inference_from_future(first_char = prev_letter,last_char = next_letter,N=len(indices),T=T,start = 1,l=l)\n",
    "\n",
    "        #print(\"From future!\")\n",
    "        #print(result)\n",
    "        a = 0\n",
    "        for i in indices:\n",
    "            list1 = list(my_str)\n",
    "            list1[i] = str(\"\".join(result[a]))\n",
    "            a = a+1\n",
    "            my_str = \"\".join(list1)\n",
    "        #print \"Result is \", my_str\n",
    "    if l:\n",
    "        return my_str,prob\n",
    "    return my_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples for  th__br__n.f_x.\n",
      "th.ybrm.n.fex.\n",
      "theqbrorn.fex.\n",
      "therbrzzn.fex.\n",
      "theybrewn.fix.\n",
      "therbr.fn.fex.\n",
      "th.mbrhen.f.x.\n",
      "theabrr.n.fix.\n",
      "thenbr.pn.fex.\n",
      "thecbry.n.fex.\n",
      "thedbresn.fix.\n",
      "samples for  _u_st__n_.to_be._nsw_r__\n",
      "auesthend.tombe.answera.\n",
      "ou.sthyns.to.be.insward.\n",
      "ourstidnk.to.be.answerre\n",
      "ourst.ine.toube.inswer.s\n",
      "tulstinnd.to.be.onsworve\n",
      "susst.tnd.toube.answer.o\n",
      "oursthent.to.be.answirri\n",
      "oursthond.toube.inswarmi\n",
      "bu.stornd.to.be..nswere.\n",
      "ousst.bng.tombe.inswere.\n",
      "samples for  i__at_._a_h_n_._e_r_i_g\n",
      "iluata.mathent.seprling\n",
      "iofaty.mathang.bepr.ing\n",
      "insath..ashing.me.r.ing\n",
      "indats.cathind.be.rging\n",
      "idsate.mathiny.wedr.ing\n",
      "im.atr.bathins.ye.r.ing\n",
      "iouaty.hathing.seereing\n",
      "ingatt.pathand.sefr.igg\n",
      "inoath.mathens.merrting\n",
      "it.at..jathind.le.r.ing\n",
      "samples for  q___t.___z._____t.__.___.__.\n",
      "qungt.ff.z.h.tint.ti.lec.e..\n",
      "qugrt.wo.z.by.wot.m..oou.an.\n",
      "qutht.jonz.tidint.ar.hen.ar.\n",
      "qur.t.nd.z.why.ct.hu.men.pl.\n",
      "qu.pt.catz..eed.t.th.hte.wh.\n",
      "qulet.thaz.tinont.is.med.cr.\n",
      "qunot.picz.h.thit.ot.the.be.\n",
      "quget.houz.dhos.t.il.t.h.r..\n",
      "qulet.ishz.le.oct..a.pan.on.\n",
      "qulet..pez.ithedt.su.th..fa.\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(test_strings)):\n",
    "    #repeat samples\n",
    "    print \"samples for \" ,test_strings[i]\n",
    "    for j in range(0,10):\n",
    "        print(problem_identify(test_strings[i],underscore_finder(test_strings[i]),T,False))\n",
    "#group_problems(underscore_finder(test_strings[0]))\n",
    "#print(test_strings[1])\n",
    "#problem_identify(test_strings[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Part 3\n",
    "Describe a method for filling in the gaps by estimating the most likely letter for each position. Hint: you need to compute\n",
    "$$\n",
    "x_{-\\alpha}^* = \\arg\\max_{x_{-\\alpha}} p(x_{-\\alpha}|x_{\\alpha})\n",
    "$$\n",
    "Implement the method and print the results for the following test strings along with the log-probability  $\\log p(x_{-\\alpha}^*,x_{\\alpha})$.\n",
    "My algorithm is like:\n",
    "\n",
    "Compute the probability for the first unknown element\n",
    "\n",
    "Take the maximum element of the probability distribution (one dimensional). Update the table with respect to new element.\n",
    "\n",
    "Assign the found element as first element. Decrease the number of multiplication by one. N--\n",
    "\n",
    "Continue until end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log prob: -3.07433486577\n",
      "the.br.an.fex.\n",
      "Log prob: -8.32284514738\n",
      "oursthend.to.be.answere.\n",
      "Log prob: -11.636089996\n",
      "in.ath.wathend.he.r.ing\n",
      "Log prob: -22.9236424228\n",
      "qur.t.thiz.the.at.an.the.an.\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(test_strings)):\n",
    "    print(problem_identify(test_strings[i],underscore_finder(test_strings[i]),T,True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Part 4\n",
    "Argmax is a good way to predict most likely sequence of strings. However, it is too much constrained, because we dont use other probabilities which may be also more likely. In order to check that we should generate all the possible strings in the domain. Then compute the each of the probabilities of the strings. Then, we can check the difference between the argmax, and the second string comes from argmax. If the difference is very less, our program continue to check the difference between the next string by popping each. By following this idea we may \n",
    "\n",
    "\n",
    "For further analysis.We can use factor graph message passing algorithm. That way it will provide better results to this problem. The algorithm will be less complicated. Since it supports more complicated forms of graphs. Thanks to that flexibility we can connect \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
