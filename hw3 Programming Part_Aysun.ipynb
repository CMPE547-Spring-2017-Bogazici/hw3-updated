{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Homework 3\n",
    "\n",
    "In this exercise we model a string of text using a Markov(1) model. For simplicity we only consider letters 'a-z'. Capital letters 'A-Z' are mapped to the corresponding ones. All remaining letters, symbols, numbers, including spaces, are denoted by '.'.\n",
    "\n",
    "\n",
    "We have a probability table $T$ where $T_{i,j} = p(x_t = j | x_{t-1} = i)$  transition model of letters in English text for $t=1,2 \\dots N$. Assume that the initial letter in a string is always a space denoted as $x_0 = \\text{'.'}$. Such a model where the probability table is always the same is sometimes called a stationary model.\n",
    "\n",
    "1. For a given $N$, write a program to sample random strings with letters $x_1, x_2, \\dots, x_N$ from $p(x_{1:N}|x_0)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from array import *\n",
    "\n",
    "alphabet = [chr(i+ord('a')) for i in range(26)]\n",
    "alphabet.append('.')\n",
    "letter2idx = {c:i for i,c in enumerate(alphabet)}\n",
    "# print (letter2idx['a'])\n",
    "T_list = []\n",
    "with open('transitions.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        T_list.append(row)\n",
    "        \n",
    "T = np.array(T_list).astype(\"float\")\n",
    "# print(T[0, 0])\n",
    "startingChar = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanString (string_input):\n",
    "    string_inputCleaned = []\n",
    "    for i in range(0, len(string_input)):\n",
    "        currString = string_input[i]\n",
    "        currLength = len(string_input[i])\n",
    "        for j in range(0, currLength):\n",
    "            if currString[j] == '.':\n",
    "                currString = currString[:j] + ' ' + currString[j+1:]\n",
    "            if j == currLength-1:\n",
    "                string_inputCleaned.append(currString)\n",
    "    return string_inputCleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function will generate random text of length N, \n",
    "# using a first order Markov Chain and the transition matrix provided in the problem statement\n",
    "def randomText (N, alphabet, T):\n",
    "    randChain = '.'\n",
    "    for i in range(1, N+1): \n",
    "        newProb = T[letter2idx[randChain[i-1]], :].copy()\n",
    "        newProb /= newProb.sum()\n",
    "        newChar = np.random.choice(alphabet, 1, p = newProb.copy())\n",
    "        randChain += newChar[0]\n",
    "    return randChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " y hesangr r  tey arevile ar t toliof pprin mam y a"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "# Example:\n",
    "# Generate random text of length 50 (50 characters) using 1st order Markov Chain\n",
    "genText = randomText(50, alphabet, T)\n",
    "genTextCleaned = cleanString(genText)\n",
    "for i in range(0, len(genText)):\n",
    "    print (genTextCleaned[i], end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transition matrix used below is the transpose of the transition matrix of English language provided for this homework. I.e., the rows correspond to the state at time t, whereas the columns are the state at time t-1.\n",
    "\n",
    "Given a string of missing letters of size N, we're asked to predict the missing letters using Markov chains. We need to find the marginal distributions of the missing letters, conditioned on the observed ones ans sample from these distributions as follows. We are asked to calculate:\n",
    "\n",
    "$$p(x_{-\\alpha}|x_{\\alpha})$$\n",
    "where $\\alpha$ denotes indices of observed letters.\n",
    "\n",
    "For instance, say we are given the string 'a _ _ _ b', where \n",
    "$N = 5$, and $x_1 = \\text{'a'}$ and $x_5 = \\text{'b'}$ are the observed letters. Similarly, $x_2 = \\text{'_'}$, $x_3 = \\text{'_'}$ and $x_4 = \\text{'_'}$ are the missing ones. Therefore we have, $\\alpha=\\{1,5\\}$ and $-\\alpha=\\{2,3,4\\}$ and the following Markov chain can be constructed:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the following joint probability distribution:\n",
    "$$p(x_{2}, x_{3}, x_{4}|x_{1} = \\text{'a'}, x_{5} = \\text{'b'}) \\propto p(x_{5} = \\text{'b'}|x_{4}) \\cdot p(x_{4}|x_{3}) \\cdot p(x_{3}|x_{2}) \\cdot p(x_{2}|x_{1} = \\text{'a'}) $$\n",
    "$$p(x_{2}|x_{1} = \\text{'a'}, x_{5} = \\text{'b'}) \\propto \\sum_{x_{3}, x_{4}} \\text{'a'}, x_{5} = \\text{'b'}) \\propto p(x_{5} = \\text{'b'}|x_{4}) \\cdot p(x_{4}|x_{3}) \\cdot p(x_{3}|x_{2}) \\cdot p(x_{2}|x_{1} = \\text{'a'})$$\n",
    "\n",
    "The marginals can be computed by distributing summation over variable states over the products of factors, which is viewed as \"messages\" being sent from one node to another. To compute the marginal probability at a node, we have to multiply the incoming messages at that node, and sum them over the other variables at other nodes which are not included in the joint probability distribution.\n",
    "\n",
    "This can be generalized for when we have N variables, $x_{N+1}$ is observed as $\\hat{x_{N+1}}$ and $x_{0}$ is observed as $\\hat{x_{0}}$ we want to compute the marginal probability at the other end of the node, $x_{1}$\n",
    "\n",
    "$$p(x_{1}| x_{0}=\\hat{x_{0}}, x_{N+1}=\\hat{x_{N+1}}) \\propto \\sum_{x_{2, 3, ... N-1}} p(x_{2}|x_{1}) ... p(x_{N}=\\hat{x_{N}}|x_{N-1})$$\n",
    "$$p(x_{1}| x_{0}=\\hat{x_{0}}, x_{N+1}=\\hat{x_{N+1}}) \\propto \\sum_{x_{N}} p(x_{N+1}=\\hat{x_{N+1}}|x_{N}) ... \\sum_{x_{n}} p(x_{n+1}|x_{n}) ... \\sum_{x_{2}} p(x_{3}|x_{2}) \\cdot p(x_{2}|x_{1}) \\cdot p(x_{1}|x_{0}=\\hat{x_{0}})$$\n",
    "\n",
    "The joint distribution above was written using the Markov property, which states that the conditional probability distribution of future states of the process (conditional on both past and present states) depends only upon the present state, not on the sequence of events that came before it. The summation above can then be factored into products of local functions of neighboring nodes.\n",
    "\n",
    "When the messages are computed from a node to another node at its right (e.g. from $x_{2}$ to $x_{3}$), we will call them \"forward messages\". Forward message, from $x_{n-1}$ to $x_{n}$ is the product of the incoming message to node $x_{n-1}$ (which is a function of $x_{n-1}$) and the local potential at node $x_{n-1}$, summed over all possible states of the variable which the message departs, $x_{n-1}$.\n",
    "\n",
    "$$m_{\\alpha} = \\sum_{x_{n-1}} p(x_{n}|x_{n-1}) m_{\\alpha}(x_{n-1})$$\n",
    "When neither $x_{n-1}$ nor $x_{n}$ are observed, this summation can also be represented as a matrix multiplication:\n",
    "\n",
    "$$m_{\\alpha} = \\textbf{T} \\cdot \\textbf{m}_{\\alpha}(x_{n-1})$$\n",
    "where, $p(x_{n}|x_{n-1})$ is the transition matrix, $\\textbf{T}$, and $m_{\\alpha}(x_{n-1})$ is a column vector.\n",
    "\n",
    "Similarly, when the messages are computed from a node to another node at its left (e.g. from $x_{3}$ to $x_{2}$), we will them \"backward messages\":\n",
    "$$m_{\\beta} = \\sum_{x_{n+1}} p(x_{n+1}|x_{n}) m_{\\beta}(x_{n+1})$$\n",
    "in matrix form:\n",
    "$$m_{\\beta} = \\textbf{m}_{\\beta}^{T}(x_{n+1}) \\cdot \\textbf{T}$$\n",
    "\n",
    "When we have observed nodes, we need to clamp the distributions. For instance, the local function, $p(x_{n}|x_{n-1})$, corresponds to the transition matrix, which is 2 dimensional. However, when one of the variables is observed, it turns into either a column or a row vector (depending on which variable is observed). If both variables are observed, then it is a scalar.\n",
    "\n",
    "The marginal probability of a node can be found by simply multiplying the incoming messages from its neighbor on the left (forward messages), and on the right (backward messages), and then normalizing the final product.\n",
    "\n",
    "$$p(x_{1}| x_{N}=\\hat{x_{N}}) \\propto m_{\\alpha} \\cdot m_{\\beta}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of simplicity, it was assumed that $x_{0}$ = '.' and $x_{N+1}$ = '.' for all strings. Two MATLAB functions, one to compute the messages transmitted between nodes, and another to predict the missing letters in a given string. It sould be noted that meassages are normalized at each step."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "function [mForward, mBackward] = computeMsg(Q, Alphabet, testString)\n",
    "currString   = testString;\n",
    "stringLength = length(currString);\n",
    "missingChar  = '_';\n",
    "ind0     = 27;\n",
    "mForward     = NaN(length(Alphabet), stringLength);\n",
    "S = [zeros(length(Alphabet)-1, 1); 1];\n",
    "% state vector\n",
    "mForward(:, 1)  = Q*S;\n",
    "for i = 1:stringLength-1\n",
    "    if currString(i) == missingChar\n",
    "        S = ones(length(Alphabet), 1);\n",
    "        S = S./sum(S);\n",
    "        mForward(:, i+1) = Q*mForward(:, i);\n",
    "        mForward(:, i+1) = mForward(:, i+1)./sum(mForward(:, i+1));\n",
    "    else\n",
    "        ind  = find(ismember(Alphabet, currString(i)));\n",
    "        % find the ind of the current character\n",
    "        S = zeros(length(Alphabet), 1);\n",
    "        S(ind) = 1;\n",
    "        % compute the msg going from the ith node to i+1th node.\n",
    "        msgIn = S'*mForward(:, i);\n",
    "        mForward(:, i+1) = Q*S.*msgIn;\n",
    "        mForward(:, i+1) = mForward(:, i+1)./sum(mForward(:, i+1));\n",
    "    end\n",
    "end\n",
    "\n",
    "mBackward = NaN(length(Alphabet), stringLength);\n",
    "% state vector\n",
    "\n",
    "S = [zeros(length(Alphabet)-1, 1); 1];\n",
    "mBackward(:, end) = S'*Q;\n",
    "\n",
    "for i = stringLength:-1:2\n",
    "    if currString(i) == missingChar\n",
    "        S = ones(length(Alphabet), 1);\n",
    "        S = S./sum(S);\n",
    "        mBackward(:, i-1) = mBackward(:, i)'*Q;\n",
    "        mBackward(:, i-1) = mBackward(:, i-1)./sum(mBackward(:, i-1));\n",
    "    else\n",
    "        ind  = find(ismember(Alphabet, currString(i)));\n",
    "        % find the ind of the current character\n",
    "        S = zeros(length(Alphabet), 1);\n",
    "        S(ind) = 1;\n",
    "        % compute the msg going from the ith node to i-1th node.\n",
    "        msgIn = S'*mBackward(:, i);\n",
    "        mBackward(:, i-1) = S'*Q.*msgIn;\n",
    "        mBackward(:, i-1) = mBackward(:, i-1)./sum(mBackward(:, i-1));\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "function [filledString] = fillStrings(Q, Alphabet, testString, flag)\n",
    "cellNo = length(testString);\n",
    "missingChar = '_';\n",
    "for j = 1:cellNo\n",
    "    currString   = testString{j};\n",
    "    stringLength = length(currString);\n",
    "    [mForward, mBackward] = computeMsg(Q, Alphabet, currString);\n",
    "    for i = 1:stringLength\n",
    "        if currString(i) == missingChar\n",
    "            p = mForward(:, i).*mBackward(:, i);\n",
    "            p = p./sum(p);\n",
    "            switch flag\n",
    "                case 0\n",
    "                    newChar = datasample(Alphabet, 1, 'Weights', p, 'Replace', false);\n",
    "                    % when flag = 0, a random sample is taken from the marginal probability distribution of the missing letter\n",
    "                case 1\n",
    "                    [~, ind] = max(p);\n",
    "                    newChar = Alphabet(ind);\n",
    "                    % when flag = 0, the letter which has the max. probability to occur in the marginal distribution is chosen\n",
    "            end\n",
    "            currString(i) = newChar;\n",
    "        end\n",
    "        if isempty(find(ismember(currString, '_')))\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    filledString{j} = currString;\n",
    "end"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q = importdata('transitions.csv',','); \n",
    "Alphabet=('a':'z');\n",
    "Alphabet(end+1) = '.';\n",
    "testString = {'th__br__n.f_x.', '_u_st__n_.to_be._nsw_r__','i__at_._a_h_n_._e_r_i_g','q___t.___z._____t.__.___.__.'};\n",
    "cellNo = length(inputString);\n",
    "Q = Q';\n",
    "missingChar = '_';\n",
    "\n",
    "[filledString] = fillStrings(Q, Alphabet, testString, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output:\n",
    "\n",
    "th.mbre.n.fix.\n",
    "\n",
    "bulst.ons.to.be.answiree\n",
    "\n",
    "imeate.vagheng.lerreing\n",
    "\n",
    "quntt.oprz.fedeit.aa.tte.on."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[filledString] = fillStrings(Q, Alphabet, testString, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output:\n",
    "\n",
    "the.br.an.fex.\n",
    "\n",
    "oursthand.to.be.answeres\n",
    "\n",
    "in.ath.wathend.he.r.ing\n",
    "\n",
    "qur.t.terz.t....t.ae.t.e.ae."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
